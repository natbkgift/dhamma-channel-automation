"""
Content Extractor Agent
‡πÅ‡∏¢‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
‡∏•‡∏ö metadata, instructions, stage directions ‡∏≠‡∏≠‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
"""

import re
from pathlib import Path
from typing import Tuple, Dict, List


class ContentExtractor:
    """
    Agent ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏¢‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    """
    
    def __init__(self):
        # Pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö metadata ‡πÅ‡∏•‡∏∞ instructions
        self.metadata_patterns = [
            # Section headers
            r'^SECTION\s+\d+/\d+.*?$',
            r'^Time:.*?$',
            r'^Words:.*?$',
            r'^Duration:.*?$',
            
            # Separator lines
            r'^[=\-_~+]{3,}$',
            
            # Markdown headings and bullets (single char lines)
            r'^[#\-]+\s*$',
            r'^[#]{1,6}\s+',  # Markdown headings ## title
            
            # Key-value metadata lines
            r'^[\w\-]+\.\s+.+$',  # title. value, target. value
            r'^[\-]\.\s+.+$',  # -. value
            
            # Timestamps
            r'\d{2}:\d{2}\s*-\s*\d{2}:\d{2}',
            r'\(\d+s\)',
            
            # Labels/Headers (‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏£‡∏¥‡∏á)
            r'^(Hook|Introduction|Main Points|Practical Application|Benefits|Conclusion|CTA)\s*(\(.*?\))?:?\s*$',
            r'^Benefits?\s*&?\s*Motivation.*$',
            r'^Conclusion\s*&?\s*CTA.*$',
            r'^VOICEOVER\s+RECORDING\s+SCRIPT.*$',
            r'^\[.*SECTION.*\]$',  # [DEMO SECTION]
            r'^POINT\s+.+$',  # POINT ‡∏´‡∏ô‡∏∂‡πà‡∏á., POINT 1
            r'^PRACTICAL.*$',  # PRACTICAL.
            # Production notes and headings
            r'^(HOOK|INTRO|INTRODUCTION|MAIN\s+POINTS|PRACTICE|PRACTICAL|BENEFITS?|CONCLUSION|CTA)\b.*$',
            r'^(END\s*SCREEN)\b.*$',
            r'^(BACKGROUND\s*MUSIC|VOICE\.|SOUND\s*EFFECTS|CITATIONS?|KEY\s*POINTS|ICONS?|FONT)\b.*$',
            
            # Technical notes
            r'^Total Duration:.*?$',
            r'^Voice Style:.*?$',
            r'^Speaking Rate:.*?$',
        ]
        
        # Pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö stage directions
        self.direction_patterns = [
            # Square brackets (‡πÅ‡∏ï‡πà‡πÄ‡∏Å‡πá‡∏ö [PAUSE] ‡πÑ‡∏ß‡πâ!)
            r'\[VISUAL:.*?\]',
            r'\[MUSIC:.*?\]',
            r'\[B-ROLL:.*?\]',
            r'\[DEMO:.*?\]',
            r'\[CUT TO:.*?\]',
            r'\[TRANSITION:.*?\]',
            r'\[TONE:.*?\]',
            r'\[CUE:.*?\]',
            r'\[TEXT[^\]]*\]',
            r'\[CITATION[^\]]*\]',
            r'\[(?!PAUSE\b).*?\]',
            # NOTE: [PAUSE] ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏•‡∏ö ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏≤‡∏Å‡∏¢‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            
            # Curly braces (technical instructions)
            r'\{.*?\}',
        ]
        
        # Pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô instruction
        self.instruction_lines = [
            r'^-\s*‡πÄ‡∏õ‡∏¥‡∏î:',
            r'^-\s*‡∏õ‡∏±‡∏ç‡∏´‡∏≤:',
            r'^-\s*‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:',
            r'^-\s*‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤',
            r'^-\s*‡∏ó‡∏≥‡πÑ‡∏°',
            r'^-\s*‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå',
            r'^-\s*‡∏™‡∏£‡∏∏‡∏õ:',
            r'^-\s*‡πÄ‡∏ä‡∏¥‡∏ç‡∏ä‡∏ß‡∏ô:',
            r'^-\s*CTA:',
            r'^-\s*‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢:',
            r'^\d+\.\s+',  # numbered lists in instructions
        ]
    
    def extract_content(self, text: str) -> Tuple[str, Dict]:
        """
        ‡πÅ‡∏¢‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        
        Returns:
            Tuple[str, Dict]: (‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏∞‡∏≠‡∏≤‡∏î, metadata)
        """
        original_length = len(text)
        lines = text.split('\n')
        
        content_lines = []
        removed_count = {
            'metadata': 0,
            'directions': 0,
            'instructions': 0,
            'empty': 0
        }
        
        for line in lines:
            original_line = line
            line = line.strip()
            
            # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á
            if not line:
                removed_count['empty'] += 1
                continue
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô metadata ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            is_metadata = False
            for pattern in self.metadata_patterns:
                if re.match(pattern, line, re.IGNORECASE):
                    is_metadata = True
                    removed_count['metadata'] += 1
                    break
            
            if is_metadata:
                continue
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô instruction line ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            is_instruction = False
            for pattern in self.instruction_lines:
                if re.match(pattern, line):
                    is_instruction = True
                    removed_count['instructions'] += 1
                    break
            
            if is_instruction:
                # ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏°‡∏µ quote ("...") ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ quote
                quotes = re.findall(r'"([^"]+)"', line)
                if quotes:
                    content_lines.extend(quotes)
                continue
            
            # ‡∏•‡∏ö stage directions ‡∏≠‡∏≠‡∏Å
            cleaned_line = line
            for pattern in self.direction_patterns:
                before = cleaned_line
                cleaned_line = re.sub(pattern, '', cleaned_line, flags=re.IGNORECASE)
                if before != cleaned_line:
                    removed_count['directions'] += 1
            
            cleaned_line = cleaned_line.strip()
            
            # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
            if cleaned_line and len(cleaned_line) > 2:  # ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 3 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
                content_lines.append(cleaned_line)
        
        # ‡∏£‡∏ß‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
        content = ' '.join(content_lines)
        
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
        content = self._post_clean(content)
        
        # ‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏¢‡∏≤‡∏ß‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö TTS)
        content = self._split_long_sentences(content)
        
        # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
        metadata = {
            'original_length': original_length,
            'original_lines': len(lines),
            'content_length': len(content),
            'content_bytes': len(content.encode('utf-8')),
            'reduction': f"{(1 - len(content)/original_length)*100:.1f}%",
            'removed': removed_count
        }
        
        return content, metadata
    
    def _post_clean(self, text: str) -> str:
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏´‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
        
        # ‡∏•‡∏ö bullet points ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
        text = re.sub(r'^\s*[-‚Ä¢¬∑]\s*', '', text)
        
        # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≥
        text = re.sub(r'\s+', ' ', text)
        
        # ‡∏•‡∏ö‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö‡πÄ‡∏õ‡∏•‡πà‡∏≤
        text = re.sub(r'\(\s*\)', '', text)
        text = re.sub(r'\[\s*\]', '', text)
        
        # ‡πÅ‡∏Å‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô
        text = re.sub(r'\s+([,.!?;:])', r'\1', text)
        text = re.sub(r'([,.!?;:])([^\s])', r'\1 \2', text)
        
        # ‡∏•‡∏ö‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏ö‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
        text = re.sub(r'[-=_~+]{3,}', ' ', text)
        
        return text.strip()
    
    def _split_long_sentences(self, text: str) -> str:
        """‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏¢‡∏≤‡∏ß‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ TTS ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ (max 180 chars/line)"""
        
        # Step 1: ‡πÅ‡∏¢‡∏Å [PAUSE] ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏™‡∏°‡∏≠
        text = re.sub(r'\s*(\[PAUSE[^\]]*\])\s*', r'\n\1\n', text)
        
        # Step 2: ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà ... ‡∏î‡πâ‡∏ß‡∏¢ . (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÑ‡∏î‡πâ)
        text = re.sub(r'\.\.\.+', '. ', text)
        
        # Step 3: ‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏î‡πâ‡∏ß‡∏¢ . ? ! ‡πÅ‡∏•‡∏∞ :
        sentences = re.split(r'([.?!:])\s+', text)
        
        # ‡∏£‡∏ß‡∏° sentence ‡∏Å‡∏±‡∏ö punctuation ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
        combined_sentences = []
        i = 0
        while i < len(sentences):
            if i + 1 < len(sentences) and sentences[i+1] in '.?!:':
                combined_sentences.append(sentences[i] + sentences[i+1])
                i += 2
            else:
                if sentences[i].strip():
                    combined_sentences.append(sentences[i])
                i += 1
        
        # Step 4: ‡∏£‡∏ß‡∏°‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 180 chars/‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î)
        lines = []
        current_line = ""
        
        for sentence in combined_sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô [PAUSE] ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏™‡∏°‡∏≠
            if sentence.startswith('[PAUSE'):
                if current_line:
                    lines.append(current_line.strip())
                    current_line = ""
                lines.append(sentence)
                continue
            
            # ‡∏ñ‡πâ‡∏≤‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô 180 chars ‡πÉ‡∏´‡πâ‡πÅ‡∏¢‡∏Å‡∏ó‡∏µ‡πà dash (-)
            if len(sentence) > 180:
                parts = sentence.split(' - ')
                for part in parts:
                    part = part.strip()
                    if len(current_line) + len(part) > 180:
                        if current_line:
                            lines.append(current_line.strip())
                        current_line = part + " "
                    else:
                        current_line += part + " - "
            elif len(current_line) + len(sentence) > 180:
                if current_line:
                    lines.append(current_line.strip())
                current_line = sentence + " "
            else:
                current_line += sentence + " "
        
        if current_line.strip():
            lines.append(current_line.strip())
        
        return '\n'.join(lines)
    
    def analyze(self, text: str) -> Dict:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á"""
        
        analysis = {
            'total_chars': len(text),
            'total_lines': len(text.split('\n')),
            'has_metadata': bool(re.search(r'SECTION\s+\d+/\d+', text)),
            'has_directions': bool(re.search(r'\[.*?\]', text)),
            'has_instructions': bool(re.search(r'^-\s+', text, re.MULTILINE)),
            'has_timestamps': bool(re.search(r'\d{2}:\d{2}', text)),
        }
        
        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô
        analysis['metadata_lines'] = len(re.findall(r'^SECTION\s+\d+/\d+', text, re.MULTILINE))
        analysis['direction_count'] = len(re.findall(r'\[.*?\]', text))
        analysis['instruction_lines'] = len(re.findall(r'^-\s+', text, re.MULTILINE))
        
        return analysis


def process_file(input_path: Path, output_path: Path = None, verbose: bool = True) -> Dict:
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå
    """
    
    extractor = ContentExtractor()
    
    # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå
    with open(input_path, 'r', encoding='utf-8') as f:
        original_text = f.read()
    
    if verbose:
        print(f"üìñ ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå: {input_path}")
        print(f"üìä ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö: {len(original_text):,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\n")
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
    if verbose:
        print("üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á:")
        analysis = extractor.analyze(original_text)
        print(f"   ‚Ä¢ ‡∏°‡∏µ Section headers: {analysis['metadata_lines']} ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î")
        print(f"   ‚Ä¢ ‡∏°‡∏µ Stage directions: {analysis['direction_count']} ‡∏ä‡∏¥‡πâ‡∏ô")
        print(f"   ‚Ä¢ ‡∏°‡∏µ Instructions: {analysis['instruction_lines']} ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î\n")
    
    # ‡πÅ‡∏¢‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
    if verbose:
        print("‚öôÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏¢‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤...\n")
    
    content, metadata = extractor.extract_content(original_text)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    if verbose:
        print("‚ú® ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:")
        print(f"   ‚Ä¢ ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏î‡∏¥‡∏°: {metadata['original_length']:,} chars")
        print(f"   ‚Ä¢ ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {metadata['content_length']:,} chars ({metadata['content_bytes']:,} bytes)")
        print(f"   ‚Ä¢ ‡∏•‡∏î‡∏•‡∏á: {metadata['reduction']}")
        print(f"\n   üóëÔ∏è ‡∏•‡∏ö‡∏≠‡∏≠‡∏Å:")
        print(f"   ‚Ä¢ Metadata: {metadata['removed']['metadata']} ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î")
        print(f"   ‚Ä¢ Directions: {metadata['removed']['directions']} ‡∏ä‡∏¥‡πâ‡∏ô")
        print(f"   ‚Ä¢ Instructions: {metadata['removed']['instructions']} ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î")
        print(f"   ‚Ä¢ ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á: {metadata['removed']['empty']} ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
    output_path = output_path or input_path.parent / f"{input_path.stem}_content_only{input_path.suffix}"
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    if verbose:
        print(f"\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå: {output_path}")
    
    metadata['input_file'] = str(input_path)
    metadata['output_file'] = str(output_path)
    
    return metadata


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='‡πÅ‡∏¢‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á')
    parser.add_argument('--input', '-i', type=str, required=True,
                       help='‡πÑ‡∏ü‡∏•‡πå input')
    parser.add_argument('--output', '-o', type=str, default=None,
                       help='‡πÑ‡∏ü‡∏•‡πå output (default: {input}_content_only.txt)')
    parser.add_argument('--quiet', '-q', action='store_true',
                       help='‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î')
    
    args = parser.parse_args()
    
    input_path = Path(args.input)
    output_path = Path(args.output) if args.output else None
    
    if not input_path.exists():
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {input_path}")
        exit(1)
    
    metadata = process_file(input_path, output_path, verbose=not args.quiet)
    
    print(f"\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
