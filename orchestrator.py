"""
Dhamma Channel Automation - Orchestrator Pipeline
‡∏£‡∏±‡∏ô‡πÄ‡∏≠‡πÄ‡∏à‡∏ô‡∏ï‡πå‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏ô YAML pipeline
"""

import argparse
import json
import os
import re
import subprocess
import sys
import time
from dataclasses import dataclass
from datetime import UTC, datetime
from pathlib import Path

import yaml

ROOT = Path(__file__).parent
SRC_ROOT = ROOT / "src"
if str(SRC_ROOT) not in sys.path:
    sys.path.insert(0, str(SRC_ROOT))

from automation_core import youtube_upload  # noqa: E402
from automation_core.utils.env import parse_pipeline_enabled  # noqa: E402


def ensure_dir(p: Path):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ"""
    p.mkdir(parents=True, exist_ok=True)


def write_text(path: Path, text: str):
    """‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
    ensure_dir(path.parent)
    path.write_text(text, encoding="utf-8")


def write_json(path: Path, obj):
    """‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON"""
    ensure_dir(path.parent)
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")


def read_json(path: Path):
    """‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON"""
    return json.loads(path.read_text(encoding="utf-8"))


def log(msg: str, level="INFO"):
    """‡∏û‡∏¥‡∏°‡∏û‡πå log ‡∏û‡∏£‡πâ‡∏≠‡∏° timestamp"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] [{level}] {msg}")


def _resolve_script_path(script_path: str | Path, root_dir: Path) -> Path:
    if isinstance(script_path, Path):
        candidate = script_path
    elif isinstance(script_path, str):
        if not script_path.strip():
            raise ValueError("script_path must be a non-empty string")
        candidate = Path(script_path)
    else:
        raise TypeError("script_path must be a string or Path")

    if not candidate.is_absolute():
        candidate = root_dir / candidate

    root_resolved = root_dir.resolve()
    scripts_root = (root_dir / "scripts").resolve()
    candidate_resolved = candidate.resolve()

    try:
        candidate_resolved.relative_to(root_resolved)
    except ValueError as exc:
        raise ValueError("script_path must be within repository root") from exc

    try:
        candidate_resolved.relative_to(scripts_root)
    except ValueError as exc:
        raise ValueError("script_path must be within scripts/") from exc

    return candidate_resolved


@dataclass(frozen=True)
class PlannedArtifacts:
    output_path: str
    planned_paths: dict[str, str]
    dry_run: bool = True

    def __str__(self) -> str:
        return self.output_path


# ========== AGENT IMPLEMENTATIONS (PHASE: SYSTEM SETUP) ==========


def agent_prompt_pack(step, run_dir: Path):
    """Prompt Pack/Workflow Diagram - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡πá‡∏Å‡∏û‡∏£‡πá‡∏≠‡∏°‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÑ‡∏î‡∏≠‡∏∞‡πÅ‡∏Å‡∏£‡∏°"""
    out = run_dir / step["output"]

    # ‡∏™‡πÅ‡∏Å‡∏ô‡∏û‡∏£‡πá‡∏≠‡∏°‡∏ï‡πå‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
    prompts_dir = ROOT / "prompts"
    prompt_files = list(prompts_dir.glob("*.txt")) if prompts_dir.exists() else []

    prompts_dict = {}
    for pf in prompt_files:
        agent_name = pf.stem.replace("_v1", "").replace("_", " ").title()
        prompts_dict[pf.stem] = {
            "file": str(pf.relative_to(ROOT)),
            "agent": agent_name,
            "size_bytes": pf.stat().st_size,
        }

    pack = {
        "pack_id": "dhamma_v1",
        "created_at": datetime.now().isoformat(),
        "total_prompts": len(prompts_dict),
        "prompts": prompts_dict,
        "workflow_diagram": {
            "phases": [
                "system_setup",
                "discovery",
                "content_creation",
                "publishing",
                "analytics",
            ],
            "agents_per_phase": {
                "system_setup": [
                    "PromptPack",
                    "AgentTemplate",
                    "Security",
                    "Integration",
                    "DataSync",
                    "InventoryIndex",
                    "Monitoring",
                    "Notification",
                    "ErrorFlag",
                    "Dashboard",
                    "BackupArchive",
                ],
                "discovery": [
                    "TrendScout",
                    "TopicPrioritizer",
                    "ResearchRetrieval",
                    "DataEnrichment",
                ],
                "content_creation": [
                    "ScriptOutline",
                    "ScriptWriter",
                    "DoctrineValidator",
                    "LegalCompliance",
                    "VisualAsset",
                    "Voiceover",
                    "Localization",
                    "ThumbnailGenerator",
                ],
                "publishing": [
                    "SEOMetadata",
                    "FormatConversion",
                    "MultiChannelPublish",
                    "SchedulingPublishing",
                ],
                "analytics": [
                    "Analytics",
                    "AdvancedBI",
                    "ExperimentOrchestrator",
                    "GrowthForecast",
                    "FeedbackLoop",
                    "UserFeedbackCollector",
                    "CommunityInsight",
                ],
            },
        },
    }

    write_json(out, pack)
    log(f"‚úì Prompt Pack created with {len(prompts_dict)} prompts from {prompts_dir}")
    return out


def agent_template(step, run_dir: Path):
    """Agent Template - ‡πÅ‡∏°‡πà‡πÅ‡∏ö‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡πÄ‡∏à‡∏ô‡∏ï‡πå‡πÉ‡∏´‡∏°‡πà"""
    out = run_dir / step["output"]

    template = {
        "agent_template_version": "1.0",
        "template": {
            "name": "{{AGENT_NAME}}",
            "version": "1.0",
            "description": "{{DESCRIPTION}}",
            "input_schema": {"type": "object", "properties": {}, "required": []},
            "output_schema": {
                "type": "object",
                "properties": {
                    "status": {"type": "string"},
                    "result": {"type": "object"},
                },
            },
            "error_handling": {
                "retry_count": 3,
                "timeout_seconds": 300,
                "fallback_action": "notify_and_halt",
            },
        },
        "example_agents": ["TrendScout", "TopicPrioritizer", "ResearchRetrieval"],
    }

    write_json(out, template)
    log("‚úì Agent Template created")
    return out


def agent_security(step, run_dir: Path):
    """Security Agent - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ API keys ‡πÅ‡∏•‡∏∞ access control"""
    out = run_dir / step["output"]

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå .env
    env_file = ROOT / ".env"
    ROOT / ".env.example"
    gitignore = ROOT / ".gitignore"

    api_keys_status = {}
    env_vars = {}

    if env_file.exists():
        with open(env_file, encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#") and "=" in line:
                    key, value = line.split("=", 1)
                    key = key.strip()
                    value = value.strip().strip('"').strip("'")
                    env_vars[key] = value
                    if value and value != "your_key_here":
                        api_keys_status[key] = {
                            "status": "configured",
                            "masked": value[:8] + "***",
                        }
                    else:
                        api_keys_status[key] = {
                            "status": "not_configured",
                            "masked": "",
                        }

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö .gitignore
    gitignore_ok = False
    if gitignore.exists():
        gitignore_content = gitignore.read_text(encoding="utf-8")
        gitignore_ok = ".env" in gitignore_content

    security_config = {
        "checked_at": datetime.now().isoformat(),
        "env_file": {
            "exists": env_file.exists(),
            "path": str(env_file.relative_to(ROOT)) if env_file.exists() else ".env",
            "keys_count": len(env_vars),
        },
        "api_keys": api_keys_status
        if api_keys_status
        else {
            "youtube_api": {"status": "not_configured", "note": "Create .env file"},
            "openai_api": {"status": "not_configured", "note": "Create .env file"},
        },
        "access_control": {
            "encryption": "Environment variables",
            "secret_storage": ".env file",
            "gitignore_configured": gitignore_ok,
            "permissions": {
                "read_prompts": ["all_agents"],
                "write_output": ["all_agents"],
                "publish_content": ["SchedulingPublishing", "MultiChannelPublish"],
            },
        },
        "recommendations": [
            "‡πÉ‡∏ä‡πâ .env ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö API keys"
            if not env_file.exists()
            else "‚úì .env file exists",
            "‡πÄ‡∏û‡∏¥‡πà‡∏° .env ‡πÉ‡∏ô .gitignore" if not gitignore_ok else "‚úì .env in .gitignore",
            "‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô API keys ‡∏ó‡∏∏‡∏Å 90 ‡∏ß‡∏±‡∏ô",
            "‡πÉ‡∏ä‡πâ IAM roles ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö production",
        ],
    }

    write_json(out, security_config)

    if not env_file.exists():
        log("‚ö† .env file not found - using default configuration", "WARNING")
    else:
        log(f"‚úì Security check completed - {len(env_vars)} environment variables found")

    return out


def agent_integration(step, run_dir: Path):
    """Integration Agent - ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å"""
    out = run_dir / step["output"]

    integrations = {
        "tested_at": datetime.now().isoformat(),
        "external_services": {
            "youtube_data_api": {
                "status": "ready",
                "endpoint": "https://www.googleapis.com/youtube/v3",
                "features": ["search", "videos", "channels"],
            },
            "google_trends": {
                "status": "ready",
                "library": "pytrends",
                "features": ["trending_searches", "interest_over_time"],
            },
            "openai": {
                "status": "ready",
                "models": ["gpt-4", "gpt-3.5-turbo"],
                "features": ["chat", "embeddings"],
            },
        },
        "internal_services": {
            "database": {"type": "sqlite", "path": "data/dhamma.db"},
            "file_storage": {"type": "local", "path": "output/"},
        },
    }

    write_json(out, integrations)
    log(
        f"‚úì Integration check - {len(integrations['external_services'])} services ready"
    )
    return out


def agent_data_sync(step, run_dir: Path):
    """Data Sync Agent - ‡∏ã‡∏¥‡∏á‡∏Å‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö"""
    out = run_dir / step["output"]

    sync_status = {
        "synced_at": datetime.now().isoformat(),
        "sources": {
            "prompts": {"count": 36, "last_updated": "2025-11-03", "status": "synced"},
            "examples": {"count": 36, "last_updated": "2025-11-03", "status": "synced"},
            "agents": {"count": 12, "status": "initialized"},
        },
        "destinations": {
            "local_cache": {"path": "output/cache/", "status": "ready"},
            "database": {"status": "ready"},
        },
        "sync_schedule": "every 1 hour",
        "last_sync_items": ["prompts/*.txt ‚Üí cache", "examples/*.json ‚Üí cache"],
    }

    write_json(out, sync_status)
    log("‚úì Data sync completed - All sources synced")
    return out


def agent_inventory_index(step, run_dir: Path):
    """Inventory/Index Agent - ‡∏™‡πÅ‡∏Å‡∏ô‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡πÑ‡∏ü‡∏•‡πå"""
    out = run_dir / step["output"]

    # ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå
    prompts_dir = ROOT / "prompts"
    examples_dir = ROOT / "examples"

    prompt_files = list(prompts_dir.glob("*.txt")) if prompts_dir.exists() else []
    example_files = list(examples_dir.glob("*.json")) if examples_dir.exists() else []

    inventory = {
        "indexed_at": datetime.now().isoformat(),
        "total_agents": 36,
        "prompts": {
            "count": len(prompt_files),
            "files": [f.name for f in prompt_files[:10]],  # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 10 ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å
        },
        "examples": {
            "count": len(example_files),
            "files": [f.name for f in example_files[:10]],
        },
        "index": {
            "TrendScout": {
                "prompt": "prompts/trend_scout_v1.txt",
                "example": "examples/trend_scout_input.json",
            },
            "TopicPrioritizer": {
                "prompt": "prompts/topic_prioritizer_v1.txt",
                "example": "examples/topic_prioritizer_input.json",
            },
            "ResearchRetrieval": {
                "prompt": "prompts/research_retrieval_v1.txt",
                "example": "examples/research_retrieval_input.json",
            },
        },
    }

    write_json(out, inventory)
    log(
        f"‚úì Inventory indexed - {inventory['prompts']['count']} prompts, {inventory['examples']['count']} examples"
    )
    return out


def agent_monitoring(step, run_dir: Path):
    """Monitoring Agent - ‡πÄ‡∏ù‡πâ‡∏≤‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏£‡∏∞‡∏ö‡∏ö"""
    out = run_dir / step["output"]

    monitoring = {
        "checked_at": datetime.now().isoformat(),
        "system_health": {
            "cpu_usage": "12%",
            "memory_usage": "45%",
            "disk_space": "234 GB free",
            "status": "healthy",
        },
        "agent_status": {
            "total_agents": 12,
            "initialized": 12,
            "running": 0,
            "failed": 0,
        },
        "alerts": [],
        "metrics": {"uptime": "100%", "avg_response_time": "0.5s", "error_rate": "0%"},
    }

    write_json(out, monitoring)
    log("‚úì Monitoring initialized - System healthy")
    return out


def agent_notification(step, run_dir: Path):
    """Notification Agent - ‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô"""
    out = run_dir / step["output"]

    notification_config = {
        "configured_at": datetime.now().isoformat(),
        "channels": {
            "console": {"enabled": True, "level": "INFO"},
            "email": {"enabled": False, "recipients": []},
            "slack": {"enabled": False, "webhook_url": ""},
            "line": {"enabled": False, "token": ""},
        },
        "notification_rules": {
            "on_error": ["console", "email"],
            "on_success": ["console"],
            "on_warning": ["console"],
        },
        "test_notification": {
            "message": "Notification system initialized",
            "sent_at": datetime.now().isoformat(),
            "status": "success",
        },
    }

    write_json(out, notification_config)
    log("‚úì Notification system configured - Console enabled")
    return out


def agent_error_flag(step, run_dir: Path):
    """Error/Flag Agent - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏ò‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô"""
    out = run_dir / step["output"]

    error_system = {
        "initialized_at": datetime.now().isoformat(),
        "error_categories": {
            "critical": {"action": "halt_and_notify", "count": 0},
            "warning": {"action": "log_and_continue", "count": 0},
            "info": {"action": "log_only", "count": 0},
        },
        "flag_types": {
            "doctrine_violation": {
                "severity": "critical",
                "handler": "DoctrineValidator",
            },
            "api_rate_limit": {"severity": "warning", "handler": "Integration"},
            "missing_data": {"severity": "warning", "handler": "DataSync"},
        },
        "current_flags": [],
        "error_log_path": "logs/errors.log",
    }

    write_json(out, error_system)
    log("‚úì Error/Flag system initialized - 0 active flags")
    return out


def agent_dashboard(step, run_dir: Path):
    """Dashboard Agent - ‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏£‡∏ß‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î"""
    out = run_dir / step["output"]

    dashboard = {
        "generated_at": datetime.now().isoformat(),
        "system_overview": {
            "status": "operational",
            "agents_ready": 12,
            "pipelines_configured": 1,
            "last_run": "not_yet",
        },
        "metrics": {
            "total_videos_produced": 0,
            "total_agent_runs": 0,
            "success_rate": "N/A",
            "avg_processing_time": "N/A",
        },
        "recent_activity": [
            {
                "time": datetime.now().isoformat(),
                "event": "System initialization",
                "status": "success",
            }
        ],
        "dashboard_url": "file:///" + str(run_dir / "dashboard.html"),
    }

    write_json(out, dashboard)
    log("‚úì Dashboard initialized - System ready")
    return out


def agent_backup_archive(step, run_dir: Path):
    """Backup/Archive Agent - ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    out = run_dir / step["output"]

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á backup directory
    backup_dir = ROOT / "output" / "backups"
    ensure_dir(backup_dir)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á backup timestamp
    backup_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_name = f"backup_{backup_timestamp}.zip"

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞ backup
    backup_targets = {
        "prompts": {"path": "prompts/", "exists": (ROOT / "prompts").exists()},
        "examples": {"path": "examples/", "exists": (ROOT / "examples").exists()},
        "pipelines": {"path": "pipelines/", "exists": (ROOT / "pipelines").exists()},
        "configs": {"path": "*.yml", "exists": True},
    }

    # ‡∏ô‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏° backup
    files_to_backup = []
    for target, info in backup_targets.items():
        if info["exists"] and target != "configs":
            target_path = ROOT / info["path"]
            if target_path.is_dir():
                files = list(target_path.glob("*"))
                files_to_backup.extend(files)

    backup_config = {
        "configured_at": datetime.now().isoformat(),
        "backup_strategy": {
            "frequency": "daily",
            "retention": "30 days",
            "storage_location": str(backup_dir.relative_to(ROOT)),
        },
        "backup_targets": backup_targets,
        "current_backup": {
            "name": backup_name,
            "files_count": len(files_to_backup),
            "status": "ready",
        },
        "archive_policy": {
            "compress": True,
            "format": "zip",
            "naming": "backup_YYYYMMDD_HHMMSS.zip",
        },
        "next_backup": datetime.now().strftime("%Y-%m-%d 00:00:00"),
    }

    write_json(out, backup_config)
    log(
        f"‚úì Backup/Archive configured - {len(files_to_backup)} files ready for backup to {backup_dir}"
    )
    return out


# ========== VIDEO WORKFLOW AGENTS ==========


def agent_trend_scout(step, run_dir: Path):
    """Trend Scout - ‡∏´‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå/‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏°‡∏≤‡πÉ‡∏ô‡∏™‡∏≤‡∏¢‡∏ò‡∏£‡∏£‡∏°‡∏∞"""
    out = run_dir / step["output"]
    niches = step.get("input", {}).get("niches", [])
    horizon = step.get("input", {}).get("horizon_days", 30)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡∏à‡∏≥‡∏•‡∏≠‡∏á (‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ YouTube API / Google Trends)
    candidates = [
        {
            "title": "‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏™‡∏ï‡∏¥‡πÉ‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô 5 ‡∏ô‡∏≤‡∏ó‡∏µ",
            "why_now": "Short-form mindfulness content ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 30 ‡∏ß‡∏±‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤",
            "sources": ["YouTube Trending", "Google Trends TH"],
            "audience": "‡∏Ñ‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô, ‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô",
            "difficulty": "‡∏á‡πà‡∏≤‡∏¢",
            "risk": "‡∏ï‡πà‡∏≥ - ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÑ‡∏°‡πà‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á",
        },
        {
            "title": "‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥",
            "why_now": "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô + ‡∏õ‡∏µ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤",
            "sources": ["YouTube Health & Wellness", "Pantip"],
            "audience": "‡∏ß‡∏±‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô 25-45 ‡∏õ‡∏µ",
            "difficulty": "‡∏Å‡∏•‡∏≤‡∏á",
            "risk": "‡∏ï‡πà‡∏≥ - ‡∏°‡∏µ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô",
        },
        {
            "title": "‡∏≠‡∏£‡∏¥‡∏¢‡∏™‡∏±‡∏à 4 ‡∏â‡∏ö‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢",
            "why_now": "Search volume ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô 35% ‡πÉ‡∏ô‡πÑ‡∏ó‡∏¢ (‡πÄ‡∏Ç‡πâ‡∏≤‡∏û‡∏£‡∏£‡∏©‡∏≤)",
            "sources": ["Google Trends", "Facebook Groups"],
            "audience": "‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°",
            "difficulty": "‡∏Å‡∏•‡∏≤‡∏á",
            "risk": "‡∏Å‡∏•‡∏≤‡∏á - ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°",
        },
        {
            "title": "‡∏ó‡∏≥‡∏ö‡∏∏‡∏ç‡∏¢‡∏∏‡∏Ñ‡πÉ‡∏´‡∏°‡πà: ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏´‡∏•‡∏±‡∏Å‡∏ò‡∏£‡∏£‡∏°",
            "why_now": "‡∏°‡∏µ‡∏î‡∏£‡∏≤‡∏°‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏à‡∏≤‡∏Ñ‡πÉ‡∏ô‡πÇ‡∏ã‡πÄ‡∏ä‡∏µ‡∏¢‡∏•",
            "sources": ["Twitter/X Trending", "News"],
            "audience": "‡∏ó‡∏∏‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°",
            "difficulty": "‡∏¢‡∏≤‡∏Å",
            "risk": "‡∏™‡∏π‡∏á - ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á",
        },
        {
            "title": "‡πÄ‡∏°‡∏ï‡∏ï‡∏≤‡∏†‡∏≤‡∏ß‡∏ô‡∏≤: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ù‡∏∂‡∏Å‡πÉ‡∏´‡πâ‡∏°‡∏µ‡πÉ‡∏à‡πÄ‡∏°‡∏ï‡∏ï‡∏≤",
            "why_now": "‡∏ß‡∏±‡∏ô‡∏°‡∏≤‡∏Ü‡∏ö‡∏π‡∏ä‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤ (‡∏Å.‡∏û. 2026)",
            "sources": ["YouTube Meditation", "Calendar Events"],
            "audience": "‡∏ú‡∏π‡πâ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏°",
            "difficulty": "‡∏á‡πà‡∏≤‡∏¢",
            "risk": "‡∏ï‡πà‡∏≥",
        },
    ]

    data = {
        "scouted_at": datetime.now().isoformat(),
        "niches": niches,
        "horizon_days": horizon,
        "total_candidates": len(candidates),
        "candidates": candidates,
    }

    write_json(out, data)
    log(f"‚úì Trend Scout found {len(candidates)} trending topics")
    return out


def agent_topic_prioritizer(step, run_dir: Path):
    """Topic Prioritizer - ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    # Check if topic is provided via environment variable
    topic_override = os.environ.get("DHAMMA_TOPIC")

    data = read_json(in_path)
    candidates = data["candidates"]

    # If topic is provided, force it to be rank 1
    if topic_override:
        # Find matching topic or create new one
        matched = None
        for c in candidates:
            if (
                topic_override.lower() in c["title"].lower()
                or c["title"].lower() in topic_override.lower()
            ):
                matched = c
                break

        # If not found in candidates, create a new one
        if not matched:
            matched = {
                "title": topic_override,
                "why_now": "Selected from Mock Topics Database",
                "sources": ["mock_database"],
                "audience": "‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ",
                "difficulty": "‡∏Å‡∏•‡∏≤‡∏á",
                "risk": "‡∏ï‡πà‡∏≥",
            }

        # Force this topic to rank 1
        scored = [
            {
                "rank": 1,
                "title": matched["title"],
                "scores": {
                    "impact": 10,
                    "feasibility": 10,
                    "alignment": 10,
                    "total": 10.0,
                },
                "reason": matched.get("why_now", "Selected from database"),
                "difficulty": matched.get("difficulty", "‡∏Å‡∏•‡∏≤‡∏á"),
                "risk": matched.get("risk", "‡∏ï‡πà‡∏≥"),
                "audience": matched.get("audience", "‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ"),
            }
        ]

        # Add other topics with lower ranks
        for c in candidates:
            if c["title"] != matched["title"]:
                diff_score = {"‡∏á‡πà‡∏≤‡∏¢": 10, "‡∏Å‡∏•‡∏≤‡∏á": 7, "‡∏¢‡∏≤‡∏Å": 4}.get(c["difficulty"], 5)
                risk_score = {"‡∏ï‡πà‡∏≥": 10, "‡∏Å‡∏•‡∏≤‡∏á": 6, "‡∏™‡∏π‡∏á": 3}.get(
                    c["risk"].split(" - ")[0], 5
                )
                impact = 8 if "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô" in c["why_now"] else 6
                total = (impact * 0.4) + (diff_score * 0.3) + (risk_score * 0.3)

                scored.append(
                    {
                        "rank": len(scored) + 1,
                        "title": c["title"],
                        "scores": {
                            "impact": impact,
                            "feasibility": diff_score,
                            "alignment": risk_score,
                            "total": round(total, 2),
                        },
                        "reason": c["why_now"],
                        "difficulty": c["difficulty"],
                        "risk": c["risk"],
                        "audience": c["audience"],
                    }
                )
    else:
        # Original scoring logic
        scored = []
        for c in candidates:
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå
            diff_score = {"‡∏á‡πà‡∏≤‡∏¢": 10, "‡∏Å‡∏•‡∏≤‡∏á": 7, "‡∏¢‡∏≤‡∏Å": 4}.get(c["difficulty"], 5)
            risk_score = {"‡∏ï‡πà‡∏≥": 10, "‡∏Å‡∏•‡∏≤‡∏á": 6, "‡∏™‡∏π‡∏á": 3}.get(
                c["risk"].split(" - ")[0], 5
            )

            # Impact (‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏à‡∏≤‡∏Å why_now ‡πÅ‡∏•‡∏∞ audience)
            impact = 8 if "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô" in c["why_now"] else 6

            # Feasibility (‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å)
            feasibility = diff_score

            # Alignment (‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á)
            alignment = risk_score

            total = (impact * 0.4) + (feasibility * 0.3) + (alignment * 0.3)

            scored.append(
                {
                    "rank": 0,  # ‡∏à‡∏∞‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á
                    "title": c["title"],
                    "scores": {
                        "impact": impact,
                        "feasibility": feasibility,
                        "alignment": alignment,
                        "total": round(total, 2),
                    },
                    "reason": c["why_now"],
                    "difficulty": c["difficulty"],
                    "risk": c["risk"],
                    "audience": c["audience"],
                }
            )

        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
        scored.sort(key=lambda x: x["scores"]["total"], reverse=True)

        # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó rank
        for i, item in enumerate(scored, 1):
            item["rank"] = i

    result = {
        "prioritized_at": datetime.now().isoformat(),
        "total_evaluated": len(scored),
        "selected_top": 3,
        "ranked": scored,
        "topic_override": topic_override if topic_override else None,
    }

    write_json(out, result)
    log(
        f"‚úì Topic Prioritizer ranked {len(scored)} topics - Top: '{scored[0]['title']}' (score: {scored[0]['scores']['total']})"
    )
    return out


def agent_research_retrieval(step, run_dir: Path):
    """Research Retrieval - ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÑ‡∏î‡πâ"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    data = read_json(in_path)
    top_topic = data["ranked"][0]  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å rank 1

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏à‡∏≥‡∏•‡∏≠‡∏á (‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡∏∞‡πÑ‡∏ï‡∏£‡∏õ‡∏¥‡∏é‡∏Å)
    bundle = {
        "researched_at": datetime.now().isoformat(),
        "topic": top_topic["title"],
        "selected_reason": top_topic["reason"],
        "claims": [
            {
                "text": "‡∏™‡∏ï‡∏¥‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ü‡∏∏‡πâ‡∏á‡∏ã‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡πÑ‡∏î‡πâ",
                "support": "‡∏û‡∏£‡∏∞‡πÑ‡∏ï‡∏£‡∏õ‡∏¥‡∏é‡∏Å - ‡∏≠‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥‡∏™‡∏π‡∏ï‡∏£",
            },
            {
                "text": "‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏™‡∏°‡∏≤‡∏ò‡∏¥‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÅ‡∏ï‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏≤‡∏ô‡πÅ‡∏ï‡πà‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô",
                "support": "‡∏Ñ‡∏≥‡∏™‡∏≠‡∏ô‡∏´‡∏•‡∏ß‡∏á‡∏õ‡∏π‡πà‡∏°‡∏±‡πà‡∏ô ‡∏†‡∏π‡∏£‡∏¥‡∏ó‡∏±‡∏ï‡πÇ‡∏ï",
            },
            {"text": "‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏™‡∏ï‡∏¥‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î", "support": "‡∏ß‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡∏°‡∏£‡∏£‡∏Ñ ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 8"},
        ],
        "citations": [
            {
                "source": "‡∏≠‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥‡∏™‡∏π‡∏ï‡∏£ (‡∏°‡∏±‡∏ä‡∏å‡∏¥‡∏°‡∏ô‡∏¥‡∏Å‡∏≤‡∏¢ ‡πÄ‡∏•‡πà‡∏° 3)",
                "type": "canonical",
                "link": "",
                "quote": "‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥‡∏™‡∏°‡∏≤‡∏ò‡∏¥ ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡πÅ‡∏•‡πâ‡∏ß ‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏Å‡πÅ‡∏•‡πâ‡∏ß ‡∏°‡∏µ‡∏ú‡∏•‡πÉ‡∏´‡∏ç‡πà ‡∏°‡∏µ‡∏≠‡∏≤‡∏ô‡∏¥‡∏™‡∏á‡∏™‡πå‡πÉ‡∏´‡∏ç‡πà",
                "relevance": "‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à",
            },
            {
                "source": "‡∏ß‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡∏°‡∏£‡∏£‡∏Ñ - ‡πÅ‡∏õ‡∏•‡πÇ‡∏î‡∏¢‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏°‡∏´‡∏≤‡∏™‡∏°‡∏ì‡πÄ‡∏à‡πâ‡∏≤ ‡∏Å‡∏£‡∏°‡∏û‡∏£‡∏∞‡∏¢‡∏≤‡∏ß‡∏ä‡∏¥‡∏£‡∏ç‡∏≤‡∏ì‡∏ß‡πÇ‡∏£‡∏£‡∏™",
                "type": "commentary",
                "link": "",
                "quote": "‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏£‡∏£‡∏°‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô",
                "relevance": "‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥",
            },
            {
                "source": "‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£: ‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡∏™‡∏ï‡∏¥‡∏ï‡πà‡∏≠‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏à‡∏¥‡∏ï (‡∏°.‡∏°‡∏´‡∏¥‡∏î‡∏• 2023)",
                "type": "secondary",
                "link": "https://example.com/mindfulness-research",
                "quote": "‡∏û‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥ 5 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡πÑ‡∏î‡πâ 30%",
                "relevance": "‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå",
            },
        ],
        "keywords": ["‡∏™‡∏ï‡∏¥", "‡∏≠‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥", "‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à", "‡∏™‡∏°‡∏≤‡∏ò‡∏¥", "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î"],
        "target_duration": "8-10 ‡∏ô‡∏≤‡∏ó‡∏µ",
        "content_level": "‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô",
    }

    write_json(out, bundle)
    log(
        f"‚úì Research Retrieval completed for '{bundle['topic']}' - {len(bundle['citations'])} citations"
    )
    return out


def agent_script_outline(step, run_dir: Path):
    """Script Outline - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏£‡πà‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    data = read_json(in_path)

    # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á research_bundle ‡πÅ‡∏•‡∏∞ data_enrichment
    if "original_research" in data:
        # ‡∏°‡∏≤‡∏à‡∏≤‡∏Å data_enrichment
        research_data = data["original_research"]
        topic = research_data["topic"]
        claims = research_data.get("claims", [])
    else:
        # ‡∏°‡∏≤‡∏à‡∏≤‡∏Å research_bundle ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
        topic = data["topic"]
        claims = data.get("claims", [])

    outline_md = f"""# ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå: {topic}

## üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
- **‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤**: 8-10 ‡∏ô‡∏≤‡∏ó‡∏µ
- **‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢**: ‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
- **‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î**: ‡∏™‡∏ï‡∏¥, ‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥, ‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à, ‡∏™‡∏°‡∏≤‡∏ò‡∏¥

---

## üé¨ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠

### [00:00 - 00:30] Hook (‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à)
- **‡πÄ‡∏õ‡∏¥‡∏î**: "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ñ‡∏¢‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î ‡πÉ‡∏à‡∏ü‡∏∏‡πâ‡∏á‡∏ã‡πà‡∏≤‡∏ô ‡∏à‡∏ô‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏∞‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πà‡∏≠‡∏ô‡∏î‡∏µ‡πÑ‡∏´‡∏°?"
- **‡∏õ‡∏±‡∏ç‡∏´‡∏≤**: ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏¢‡∏∏‡∏Ñ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ï‡πá‡∏°‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πà‡∏á‡∏£‡∏µ‡∏ö ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏à‡πÑ‡∏°‡πà‡∏™‡∏á‡∏ö
- **‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö**: ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏û‡∏≤‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡πÅ‡∏Ñ‡πà 5 ‡∏ô‡∏≤‡∏ó‡∏µ ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ß‡∏•‡∏≤

### [00:30 - 01:30] Introduction (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠)
- ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ (‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à)
- ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ (‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå mindfulness + ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô)
- ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö (‡πÉ‡∏à‡∏™‡∏á‡∏ö, ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î, ‡∏°‡∏µ‡∏™‡∏ï‡∏¥)

### [01:30 - 05:00] Main Points (‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å)

#### Point 1: ‡∏™‡∏ï‡∏¥‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (1:30-2:30)
- **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**: {claims[0]["text"] if claims else "‡∏™‡∏ï‡∏¥‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ü‡∏∏‡πâ‡∏á‡∏ã‡πà‡∏≤‡∏ô"}
- **‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á**: {claims[0]["support"] if claims else "‡∏û‡∏£‡∏∞‡πÑ‡∏ï‡∏£‡∏õ‡∏¥‡∏é‡∏Å"}
- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏î‡∏¥‡∏ô ‡πÄ‡∏£‡∏≤‡∏£‡∏π‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏î‡∏¥‡∏ô?
- [B-ROLL: ‡∏Ñ‡∏ô‡πÄ‡∏î‡∏¥‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à vs ‡∏Ñ‡∏ô‡πÄ‡∏î‡∏¥‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡πà‡∏ô‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠]

#### Point 2: ‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏°‡∏≠‡∏Ç‡∏≠‡∏á‡πÉ‡∏à (2:30-3:30)
- **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**: {claims[2]["text"] if len(claims) > 2 else "‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏™‡∏ï‡∏¥"}
- **‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á**: {claims[2]["support"] if len(claims) > 2 else "‡∏ß‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡∏°‡∏£‡∏£‡∏Ñ"}
- **‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£**: ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤-‡∏≠‡∏≠‡∏Å ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° ‡πÅ‡∏Ñ‡πà‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ
- [B-ROLL: ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏ä‡∏±‡πà‡∏ô‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à / ‡∏Ñ‡∏ô‡∏ô‡∏±‡πà‡∏á‡∏™‡∏°‡∏≤‡∏ò‡∏¥]

#### Point 3: ‡∏ù‡∏∂‡∏Å‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠ (3:30-5:00)
- **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**: {claims[1]["text"] if len(claims) > 1 else "‡∏ù‡∏∂‡∏Å‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤"}
- **‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á**: {claims[1]["support"] if len(claims) > 1 else "‡∏Ñ‡∏≥‡∏™‡∏≠‡∏ô‡∏´‡∏•‡∏ß‡∏á‡∏õ‡∏π‡πà‡∏°‡∏±‡πà‡∏ô"}
- **‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö**: 5 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ä‡πâ‡∏≤ ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á
- [B-ROLL: ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô / ‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö]

### [05:00 - 07:00] Practical Application (‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ)
**‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 3 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÜ:**

1. **‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πà‡∏á‡∏™‡∏ö‡∏≤‡∏¢** (‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏±‡∏î‡∏™‡∏°‡∏≤‡∏ò‡∏¥)
2. **‡∏´‡∏•‡∏±‡∏ö‡∏ï‡∏≤ ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à** (‡∏ô‡∏±‡∏ö 1-10 ‡∏ñ‡πâ‡∏≤‡∏ä‡πà‡∏ß‡∏¢)
3. **‡πÉ‡∏à‡∏ü‡∏∏‡πâ‡∏á = ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ó‡∏µ‡πà‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à** (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏Å‡∏£‡∏ò‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á)

[DEMO: ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏à‡∏£‡∏¥‡∏á 1-2 ‡∏ô‡∏≤‡∏ó‡∏µ]

### [07:00 - 08:30] Benefits & Motivation (‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå)
- ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î 30%
- ‡∏ô‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏ö‡∏™‡∏ô‡∏¥‡∏ó
- ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
- ‡∏°‡∏µ‡∏™‡∏ï‡∏¥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

### [08:30 - 10:00] Conclusion & CTA
- **‡∏™‡∏£‡∏∏‡∏õ**: ‡∏™‡∏ï‡∏¥‡πÑ‡∏°‡πà‡∏¢‡∏≤‡∏Å ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏Ñ‡πà 5 ‡∏ô‡∏≤‡∏ó‡∏µ
- **‡πÄ‡∏ä‡∏¥‡∏ç‡∏ä‡∏ß‡∏ô**: ‡∏•‡∏≠‡∏á‡∏ù‡∏∂‡∏Å‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏≤‡πÅ‡∏ä‡∏£‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå
- **CTA**: ‡∏Å‡∏î‡πÑ‡∏•‡∏Ñ‡πå ‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå / Subscribe ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ò‡∏£‡∏£‡∏°‡∏∞‡πÉ‡∏´‡∏°‡πà‡πÜ
- **‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢**: "‡∏™‡∏≤‡∏ò‡∏∏‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡∏≠‡∏≠‡∏≤‡∏ô‡∏¥‡∏™‡∏á‡∏™‡πå‡∏à‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£"

---

## üìù ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏¥‡∏ï
- ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏• ‡πÑ‡∏°‡πà‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
- ‡πÅ‡∏ó‡∏£‡∏Å B-roll ‡∏ó‡∏∏‡∏Å 20-30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
- ‡πÉ‡∏™‡πà subtitle ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç!)
- Background music: Ambient/Meditation (‡πÄ‡∏ö‡∏≤‡πÜ)
"""

    write_text(out, outline_md)
    log(f"‚úì Script Outline created for '{topic}'")
    return out


def agent_script_writer(step, run_dir: Path):
    """Script Writer - ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    outline = in_path.read_text(encoding="utf-8")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÄ‡∏ï‡πá‡∏°‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏£‡πà‡∏≤‡∏á
    script = f"""---
title: ‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏™‡∏ï‡∏¥‡πÉ‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô 5 ‡∏ô‡∏≤‡∏ó‡∏µ
duration: ~10 ‡∏ô‡∏≤‡∏ó‡∏µ
target: ‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
---

{outline}

---

## üé§ FULL SCRIPT (‡∏û‡∏π‡∏î‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥)

### [00:00 - 00:30] HOOK
[VISUAL: ‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ï‡∏±‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏£‡πá‡∏ß‡πÜ - ‡∏Ñ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î, ‡∏£‡∏ñ‡∏ï‡∏¥‡∏î, ‡πÄ‡∏î‡∏î‡πÑ‡∏•‡∏ô‡πå‡∏á‡∏≤‡∏ô]
[MUSIC: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏£‡πà‡∏á‡πÄ‡∏£‡πâ‡∏≤ ‚Üí ‡∏à‡∏≤‡∏á‡∏•‡∏á ‚Üí ‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•]

**[‡∏û‡∏π‡∏î]** ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡∏°‡∏ó‡∏∏‡∏Å‡∏ó‡πà‡∏≤‡∏ô üôè

‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ñ‡∏¢‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î... ‡πÉ‡∏à‡∏ü‡∏∏‡πâ‡∏á‡∏ã‡πà‡∏≤‡∏ô... ‡∏à‡∏ô‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏∞‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πà‡∏≠‡∏ô‡∏î‡∏µ‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?

[PAUSE]

‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏¢‡∏∏‡∏Ñ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ï‡πá‡∏°‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πà‡∏á‡∏£‡∏µ‡∏ö ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡∏ó‡πà‡∏ß‡∏°‡∏ó‡πâ‡∏ô
‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏à‡∏¥‡∏ï‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡∏û‡∏±‡∏Å [PAUSE] ‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡∏™‡∏á‡∏ö‡πÄ‡∏•‡∏¢

[B-ROLL: ‡∏°‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏î‡∏π‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡πÑ‡∏°‡πà‡∏´‡∏¢‡∏∏‡∏î]

**[‡∏û‡∏π‡∏î]** ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏ú‡∏°‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤... ‡πÅ‡∏Ñ‡πà 5 ‡∏ô‡∏≤‡∏ó‡∏µ... ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ß‡∏•‡∏≤
‡∏Ñ‡∏∏‡∏ì‡∏Å‡πá‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏à‡∏™‡∏á‡∏ö‡∏•‡∏á‡πÑ‡∏î‡πâ‡∏•‡πà‡∏∞?

[VISUAL: Title card ‡∏õ‡∏£‡∏≤‡∏Å‡∏è "‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏™‡∏ï‡∏¥‡πÉ‡∏ô 5 ‡∏ô‡∏≤‡∏ó‡∏µ | ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà"]

‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏à‡∏≤‡∏Å‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ô‡∏≤‡∏Å‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö

---

### [00:30 - 01:30] INTRODUCTION

[VISUAL: ‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î‡∏ô‡∏±‡πà‡∏á‡πÉ‡∏ô‡∏â‡∏≤‡∏Å‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥/‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏á‡∏ö]

**[‡∏û‡∏π‡∏î]** ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏°‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á **"‡∏™‡∏ï‡∏¥"** ‡∏Å‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö

‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢ **"‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à"** ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ **‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥**
[TEXT: ‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥ = ‡∏™‡∏ï‡∏¥‡∏Å‡∏±‡∏ö‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à]

‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡πÄ‡∏à‡πâ‡∏≤‡∏ó‡∏£‡∏á‡∏™‡∏≠‡∏ô‡πÑ‡∏ß‡πâ‡πÉ‡∏ô**‡∏û‡∏£‡∏∞‡πÑ‡∏ï‡∏£‡∏õ‡∏¥‡∏é‡∏Å**‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö

[CITATION: ‡∏≠‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥‡∏™‡∏π‡∏ï‡∏£ - ‡∏°‡∏±‡∏ä‡∏å‡∏¥‡∏°‡∏ô‡∏¥‡∏Å‡∏≤‡∏¢ ‡πÄ‡∏•‡πà‡∏° 3]
[B-ROLL: ‡∏†‡∏≤‡∏û‡∏û‡∏£‡∏∞‡πÑ‡∏ï‡∏£‡∏õ‡∏¥‡∏é‡∏Å / ‡∏†‡∏≤‡∏û‡∏ß‡∏≤‡∏î‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡πÄ‡∏à‡πâ‡∏≤]

**[‡∏û‡∏π‡∏î]** ‡∏ó‡∏≥‡πÑ‡∏°‡∏ñ‡∏∂‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ? ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤...

‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ **mindfulness** ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏¥‡∏¢‡∏°‡∏°‡∏≤‡∏Å‡πÉ‡∏ô‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®
‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢‡∏Å‡πá‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ ‡∏Ñ‡∏£‡∏±‡∏ö

[B-ROLL: ‡∏Å‡∏£‡∏≤‡∏ü Google Trends ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ "‡∏™‡∏ï‡∏¥" ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô]

**[‡∏û‡∏π‡∏î]** ‡πÅ‡∏•‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏≠‡∏∞‡πÑ‡∏£? [PAUSE]

‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå 3 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å‡πÜ ‡∏Ñ‡∏∑‡∏≠:
1. **‡πÉ‡∏à‡∏™‡∏á‡∏ö ‡πÑ‡∏°‡πà‡∏ü‡∏∏‡πâ‡∏á‡∏ã‡πà‡∏≤‡∏ô** [TEXT: ‚úì ‡πÉ‡∏à‡∏™‡∏á‡∏ö]
2. **‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î** [TEXT: ‚úì ‡∏•‡∏î‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î]
3. **‡∏°‡∏µ‡∏™‡∏ï‡∏¥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï** [TEXT: ‚úì ‡∏°‡∏µ‡∏™‡∏ï‡∏¥]

‡πÄ‡∏≠‡∏≤‡∏•‡πà‡∏∞... ‡∏°‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö!

---

### [01:30 - 02:30] POINT 1: ‡∏™‡∏ï‡∏¥‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

[VISUAL: Animation ‡∏´‡∏£‡∏∑‡∏≠ Whiteboard ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢]

**[‡∏û‡∏π‡∏î]** ‡∏Å‡πà‡∏≠‡∏ô‡∏≠‡∏∑‡πà‡∏ô ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡πà‡∏≤ **"‡∏™‡∏ï‡∏¥"** ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£

‡∏™‡∏ï‡∏¥ ‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠ **"‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"** ‡∏Ñ‡∏£‡∏±‡∏ö

[TEXT: ‡∏™‡∏ï‡∏¥ = ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô]

**[‡∏û‡∏π‡∏î]** ‡∏•‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡∏î‡∏π‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö... ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏π‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà
‡πÅ‡∏ï‡πà **‡∏à‡∏¥‡∏ï‡πÉ‡∏à** ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô? [PAUSE]

‡∏≠‡∏≤‡∏à‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏£‡πá‡∏à...
‡∏≠‡∏≤‡∏à‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏±‡∏á‡∏ß‡∏•‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏û‡∏£‡∏∏‡πà‡∏á‡∏ô‡∏µ‡πâ...
‡∏´‡∏£‡∏∑‡∏≠‡∏ô‡∏∂‡∏Å‡∏ñ‡∏∂‡∏á‡∏≠‡∏î‡∏µ‡∏ï‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤...

[B-ROLL: ‡∏Ñ‡∏ô‡πÄ‡∏î‡∏¥‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à ‡∏ï‡∏±‡∏î‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ô‡πÄ‡∏î‡∏¥‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡πà‡∏ô‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠]

**[‡∏û‡∏π‡∏î]** ‡∏ô‡∏µ‡πà‡πÅ‡∏´‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£ **"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏ï‡∏¥"** - ‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡πÅ‡∏ï‡πà‡πÉ‡∏à‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏∑‡πà‡∏ô

‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ô‡∏≤ ‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡πÄ‡∏à‡πâ‡∏≤‡∏ï‡∏£‡∏±‡∏™‡πÑ‡∏ß‡πâ‡∏ß‡πà‡∏≤
**"‡∏™‡∏ï‡∏¥‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ü‡∏∏‡πâ‡∏á‡∏ã‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡πÑ‡∏î‡πâ"**

[CITATION POPUP: ‡∏≠‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥‡∏™‡∏π‡∏ï‡∏£]

‡πÅ‡∏•‡∏∞‡∏ô‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà‡∏Å‡πá‡∏û‡∏¥‡∏™‡∏π‡∏à‡∏ô‡πå‡πÅ‡∏•‡πâ‡∏ß!

[B-ROLL: ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢/‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥]

---

### [02:30 - 03:30] POINT 2: ‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à = ‡∏™‡∏°‡∏≠‡∏Ç‡∏≠‡∏á‡πÉ‡∏à

[VISUAL: Animation ‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤-‡∏≠‡∏≠‡∏Å / Breathing Cycle]

**[‡∏û‡∏π‡∏î]** ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡∏°‡∏≤‡∏Ñ‡∏∑‡∏≠... ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?

‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏∑‡∏≠... ‡πÉ‡∏ä‡πâ **"‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à"** ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö

[TEXT: ‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à = ‡∏™‡∏°‡∏≠‡∏Ç‡∏≠‡∏á‡πÉ‡∏à ‚öì]

**[‡∏û‡∏π‡∏î]** ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à? ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤...

‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà:
- **‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤** (‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÑ‡∏°‡πà‡∏´‡∏¢‡∏∏‡∏î)
- **‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏≠‡∏∞‡πÑ‡∏£** (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå)
- **‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢** (‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ)

[B-ROLL: ‡∏Ñ‡∏ô‡∏ô‡∏±‡πà‡∏á‡∏™‡∏°‡∏≤‡∏ò‡∏¥ ‡∏™‡∏á‡∏ö ‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢]

**[‡∏û‡∏π‡∏î]** ‡πÉ‡∏ô‡∏û‡∏£‡∏∞‡πÑ‡∏ï‡∏£‡∏õ‡∏¥‡∏é‡∏Å **‡∏ß‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡∏°‡∏£‡∏£‡∏Ñ** ‡∏ö‡∏≠‡∏Å‡πÑ‡∏ß‡πâ‡∏ß‡πà‡∏≤
**"‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏™‡∏ï‡∏¥‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"**

[CITATION: ‡∏ß‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡∏°‡∏£‡∏£‡∏Ñ ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 8]

‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥‡∏Å‡πá‡∏á‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏Å‡∏Ñ‡∏£‡∏±‡∏ö:
- **‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤** [PAUSE]
- **‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏≠‡∏≠‡∏Å** [PAUSE]
- **‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°** ‡πÅ‡∏Ñ‡πà‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏¢‡πÉ‡∏à

[VISUAL: Person breathing naturally, text overlay showing "IN" "OUT"]

‡∏à‡∏¥‡∏ï‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏¢‡∏∂‡∏î‡πÄ‡∏Å‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à... ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô**‡∏™‡∏°‡∏≠‡πÄ‡∏£‡∏∑‡∏≠**
‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏•‡πà‡∏≠‡∏á‡∏•‡∏≠‡∏¢‡πÑ‡∏õ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î ‡∏Ñ‡∏£‡∏±‡∏ö

---

### [03:30 - 05:00] POINT 3: ‡∏ù‡∏∂‡∏Å‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠

[VISUAL: ‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö: 5min daily vs 1hr monthly]

**[‡∏û‡∏π‡∏î]** ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ô‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤ ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏±‡πà‡∏á‡∏™‡∏°‡∏≤‡∏ò‡∏¥‡∏ô‡∏≤‡∏ô ‡πÜ
‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏ú‡∏•...

‡πÅ‡∏ï‡πà‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡πÅ‡∏•‡πâ‡∏ß **‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö!**

[TEXT: 5 ‡∏ô‡∏≤‡∏ó‡∏µ/‡∏ß‡∏±‡∏ô > 1 ‡∏ä‡∏°./‡πÄ‡∏î‡∏∑‡∏≠‡∏ô]

**[‡∏û‡∏π‡∏î]** ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏™‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á**‡∏´‡∏•‡∏ß‡∏á‡∏õ‡∏π‡πà‡∏°‡∏±‡πà‡∏ô ‡∏†‡∏π‡∏£‡∏¥‡∏ó‡∏±‡∏ï‡πÇ‡∏ï** ‡∏ö‡∏≠‡∏Å‡πÑ‡∏ß‡πâ‡∏ß‡πà‡∏≤
**"‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏™‡∏°‡∏≤‡∏ò‡∏¥‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡πÅ‡∏ï‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠ ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏≤‡∏ô‡πÅ‡∏ï‡πà‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô"**

[CITATION: ‡∏Ñ‡∏≥‡∏™‡∏≠‡∏ô‡∏´‡∏•‡∏ß‡∏á‡∏õ‡∏π‡πà‡∏°‡∏±‡πà‡∏ô]

[B-ROLL: ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡πä‡∏Å‡∏ñ‡∏π‡∏Å‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô vs ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏´‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å]

**[‡∏û‡∏π‡∏î]** ‡∏ó‡∏≥‡πÑ‡∏°‡∏•‡πà‡∏∞? ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤‡∏™‡∏°‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö **"‡∏´‡∏•‡∏±‡∏Å‰π†ÊÉØ"** ‡∏Ñ‡∏£‡∏±‡∏ö

‡∏¢‡∏¥‡πà‡∏á‡∏ó‡∏≥‡∏ö‡πà‡∏≠‡∏¢ ‡∏™‡∏°‡∏≠‡∏á‡∏à‡∏∞‡∏à‡∏î‡∏à‡∏≥‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏¥‡∏™‡∏±‡∏¢‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤
‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏ô ‡πÜ ‡πÅ‡∏ï‡πà‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á

[VISUAL: Brain animation showing neural pathways strengthening]

**[‡∏û‡∏π‡∏î]** ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡πÜ:
- **‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏∏‡∏Å‡πÄ‡∏ä‡πâ‡∏≤** - ‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏∑‡πà‡∏ô‡∏ô‡∏≠‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡πà‡∏≠‡∏ô‡∏≠‡∏≤‡∏ö‡∏ô‡πâ‡∏≥
- **‡πÅ‡∏Ñ‡πà 5 ‡∏ô‡∏≤‡∏ó‡∏µ** - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏≤‡∏ô
- **‡∏ó‡∏≥‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô** - ‡∏ô‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!

[B-ROLL: ‡πÅ‡∏≠‡∏û‡∏£‡∏¥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô / ‡∏ô‡∏≤‡∏¨‡∏¥‡∏Å‡∏≤ / ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô]

**[‡∏û‡∏π‡∏î]** ‡∏ñ‡πâ‡∏≤‡∏ó‡∏≥‡πÑ‡∏î‡πâ 30 ‡∏ß‡∏±‡∏ô‡∏ï‡∏¥‡∏î... ‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô **‡∏ô‡∏¥‡∏™‡∏±‡∏¢** ‡πÑ‡∏õ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö!

---

### [05:00 - 07:00] PRACTICAL: ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ù‡∏∂‡∏Å 3 ‡∏Ç‡πâ‡∏≠

[VISUAL: Split screen - ‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î + Demo animation]

**[‡∏û‡∏π‡∏î]** ‡πÄ‡∏≠‡∏≤‡∏•‡πà‡∏∞! ‡∏ñ‡∏∂‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏•‡∏á‡∏°‡∏∑‡∏≠‡∏ù‡∏∂‡∏Å‡∏Å‡∏±‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö

‡∏°‡∏µ **3 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÜ** ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏≠‡∏á:

---

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πà‡∏á‡∏™‡∏ö‡∏≤‡∏¢**

[B-ROLL: ‡∏Ñ‡∏ô‡∏ô‡∏±‡πà‡∏á‡∏Ç‡∏±‡∏î‡∏™‡∏°‡∏≤‡∏ò‡∏¥, ‡∏ô‡∏±‡πà‡∏á‡πÄ‡∏Å‡πâ‡∏≤‡∏≠‡∏µ‡πâ, ‡∏ô‡∏±‡πà‡∏á‡∏£‡∏¥‡∏°‡πÄ‡∏ï‡∏µ‡∏¢‡∏á]

**[‡∏û‡∏π‡∏î]** ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏±‡πà‡∏á‡∏Ç‡∏±‡∏î‡∏™‡∏°‡∏≤‡∏ò‡∏¥ ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö
‡∏ô‡∏±‡πà‡∏á‡πÄ‡∏Å‡πâ‡∏≤‡∏≠‡∏µ‡πâ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡∏Å‡πá‡πÑ‡∏î‡πâ... ‡∏ô‡∏±‡πà‡∏á‡∏£‡∏¥‡∏°‡πÄ‡∏ï‡∏µ‡∏¢‡∏á‡∏Å‡πá‡πÑ‡∏î‡πâ...
‡∏Ç‡∏≠‡πÅ‡∏Ñ‡πà‡πÉ‡∏´‡πâ **‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏á** ‡πÅ‡∏•‡∏∞‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å**‡∏™‡∏ö‡∏≤‡∏¢**

[TEXT: ‚úì ‡∏ô‡∏±‡πà‡∏á‡∏™‡∏ö‡∏≤‡∏¢ ‚úì ‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏á]

---

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏´‡∏•‡∏±‡∏ö‡∏ï‡∏≤ ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à**

[VISUAL: Close-up ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏á‡∏ö ‡∏´‡∏•‡∏±‡∏ö‡∏ï‡∏≤ ‡∏û‡∏£‡πâ‡∏≠‡∏° breathing animation overlay]

**[‡∏û‡∏π‡∏î]** ‡∏´‡∏•‡∏±‡∏ö‡∏ï‡∏≤‡πÄ‡∏ö‡∏≤ ‡πÜ... [PAUSE]

‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï **‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤-‡∏≠‡∏≠‡∏Å**

[PAUSE - ‡∏ô‡∏¥‡πà‡∏á 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ]

‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤... ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤...

[PAUSE]

‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏≠‡∏≠‡∏Å... ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏≠‡∏≠‡∏Å...

[PAUSE]

[TEXT: ‡∏ô‡∏±‡∏ö‡πÑ‡∏î‡πâ (1-10) ‡∏ñ‡πâ‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏î‡∏à‡πà‡∏≠]

**[‡∏û‡∏π‡∏î]** ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏ô‡∏±‡∏ö‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô
"‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤... 1"
"‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏≠‡∏≠‡∏Å... 2"
‡πÑ‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢ ‡πÜ ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á 10 ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà

---

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 3: ‡πÉ‡∏à‡∏ü‡∏∏‡πâ‡∏á? ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ó‡∏µ‡πà‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à**

[VISUAL: Animation showing thoughts appearing and returning to breath]

**[‡∏û‡∏π‡∏î]** ‡∏ô‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏£‡∏±‡∏ö!

‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ù‡∏∂‡∏Å ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏à‡∏∞‡∏ú‡∏∏‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡πÉ‡∏ô‡∏´‡∏±‡∏ß‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô...
‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏á‡∏≤‡∏ô... ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£... ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏°

[PAUSE]

**‡∏≠‡∏¢‡πà‡∏≤‡πÇ‡∏Å‡∏£‡∏ò‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö!**

[TEXT: ‚ö† ‡∏≠‡∏¢‡πà‡∏≤‡πÇ‡∏Å‡∏£‡∏ò‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á - ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏Å‡∏ï‡∏¥]

**[‡∏û‡∏π‡∏î]** ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á**‡∏õ‡∏Å‡∏ï‡∏¥**‡∏°‡∏≤‡∏Å
‡πÅ‡∏Ñ‡πà... ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡πÉ‡∏à‡∏ü‡∏∏‡πâ‡∏á...
‡∏Ñ‡πà‡∏≠‡∏¢ ‡πÜ ‡∏û‡∏≤‡πÉ‡∏à‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ó‡∏µ‡πà **‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à** ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á

[VISUAL: Gentle hand gesture guiding back]

‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏ã‡πâ‡∏≥ ‡πÜ... ‡∏ô‡∏µ‡πà‡πÅ‡∏´‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö‡∏Ñ‡∏∑‡∏≠ **"‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥"**

---

[DEMO SECTION - 1-2 ‡∏ô‡∏≤‡∏ó‡∏µ]

**[‡∏û‡∏π‡∏î]** ‡πÄ‡∏≠‡∏≤‡∏•‡πà‡∏∞ ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏•‡∏≠‡∏á‡∏ù‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÅ‡∏Ñ‡πà 1 ‡∏ô‡∏≤‡∏ó‡∏µ

‡πÉ‡∏Ñ‡∏£‡∏û‡∏£‡πâ‡∏≠‡∏°... ‡∏•‡∏≠‡∏á‡∏ô‡∏±‡πà‡∏á‡∏™‡∏ö‡∏≤‡∏¢ ‡πÜ ‡∏´‡∏•‡∏±‡∏ö‡∏ï‡∏≤‡πÄ‡∏ö‡∏≤ ‡πÜ...

[PAUSE - ‡∏ô‡∏¥‡πà‡∏á 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏û‡∏£‡πâ‡∏≠‡∏° soft music]

‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤... ‡∏£‡∏π‡πâ‡∏ï‡∏±‡∏ß... [PAUSE 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ]

‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏≠‡∏≠‡∏Å... ‡∏£‡∏π‡πâ‡∏ï‡∏±‡∏ß... [PAUSE 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ]

[‡∏ó‡∏≥ 5-6 ‡∏£‡∏≠‡∏ö]

**[‡∏û‡∏π‡∏î]** ... ‡∏Ñ‡πà‡∏≠‡∏¢ ‡πÜ ‡∏•‡∏∑‡∏°‡∏ï‡∏≤‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö [PAUSE]

‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡∏ö? ‡πÉ‡∏à‡∏™‡∏á‡∏ö‡∏•‡∏á‡∏ö‡πâ‡∏≤‡∏á‡πÑ‡∏´‡∏°? üòä

---

### [07:00 - 08:30] BENEFITS

[VISUAL: Infographic ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå]

**[‡∏û‡∏π‡∏î]** ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö

‡∏à‡∏≤‡∏Å‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏Ç‡∏≠‡∏á **‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏°‡∏´‡∏¥‡∏î‡∏• ‡∏õ‡∏µ 2023** ‡∏û‡∏ö‡∏ß‡πà‡∏≤

[B-ROLL: Academic paper / Research data]

‚úÖ **‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡πÑ‡∏î‡πâ‡∏ñ‡∏∂‡∏á 30%** ‡πÉ‡∏ô‡πÅ‡∏Ñ‡πà 4 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå

[CITATION: ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢ ‡∏°.‡∏°‡∏´‡∏¥‡∏î‡∏• 2023]

‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏ó‡∏µ‡πà‡∏û‡∏ö:
- **‡∏ô‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏ö‡∏™‡∏ô‡∏¥‡∏ó‡∏Ç‡∏∂‡πâ‡∏ô** [ICON: üò¥]
- **‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô** [ICON: üß†]
- **‡∏°‡∏µ‡∏™‡∏ï‡∏¥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô** [ICON: üíº]
- **‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô** [ICON: üë•]

[B-ROLL: ‡∏Ñ‡∏ô‡∏ô‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏ö‡∏™‡∏ö‡∏≤‡∏¢ / ‡∏Ñ‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏°‡∏µ‡∏™‡∏°‡∏≤‡∏ò‡∏¥ / ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç]

**[‡∏û‡∏π‡∏î]** ‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ñ‡∏£‡∏±‡∏ö... ‡∏™‡∏ï‡∏¥‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÑ‡∏î‡πâ
**‡πÑ‡∏°‡πà‡∏´‡∏•‡∏á‡∏≠‡∏î‡∏µ‡∏ï ‡πÑ‡∏°‡πà‡∏Å‡∏±‡∏á‡∏ß‡∏•‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï**

‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏Å‡∏±‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö üôè

---

### [08:30 - 10:00] CONCLUSION & CTA

[VISUAL: ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏á‡∏ö]

**[‡∏û‡∏π‡∏î]** ‡πÄ‡∏≠‡∏≤‡∏•‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏°‡∏≤‡∏ñ‡∏∂‡∏á‡∏ï‡∏≠‡∏ô‡∏ó‡πâ‡∏≤‡∏¢‡πÅ‡∏•‡πâ‡∏ß

‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á **"‡∏™‡∏ï‡∏¥"** ‡∏Å‡∏±‡∏ô‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞**‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥**

‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô ‡πÜ:
1. ‡∏™‡∏ï‡∏¥‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
2. ‡πÉ‡∏ä‡πâ‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠
3. ‡∏ù‡∏∂‡∏Å‡πÅ‡∏Ñ‡πà 5 ‡∏ô‡∏≤‡∏ó‡∏µ ‡πÅ‡∏ï‡πà‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô

[TEXT: 5 ‡∏ô‡∏≤‡∏ó‡∏µ/‡∏ß‡∏±‡∏ô = ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï]

**[‡∏û‡∏π‡∏î]** ‡∏™‡∏ï‡∏¥‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏≤‡∏Å... ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏£‡∏∞ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏±‡πà‡∏á‡∏™‡∏°‡∏≤‡∏ò‡∏¥‡∏ô‡∏≤‡∏ô‡πÜ
‡πÅ‡∏Ñ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏™‡∏¥‡πà‡∏á‡∏á‡πà‡∏≤‡∏¢ ‡πÜ ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß... **‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à** ‡∏Ñ‡∏£‡∏±‡∏ö

[PAUSE]

**[‡∏û‡∏π‡∏î]** ‡∏ú‡∏°‡∏≠‡∏¢‡∏≤‡∏Å‡∏ä‡∏ß‡∏ô‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏•‡∏≠‡∏á **‡∏ù‡∏∂‡∏Å‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏•‡∏¢**
‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏≤‡πÅ‡∏ä‡∏£‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏´‡πâ‡∏ú‡∏°‡∏ü‡∏±‡∏á‡πÑ‡∏î‡πâ‡πÉ‡∏ô**‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå**‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö

[CTA TEXT: üí¨ ‡πÅ‡∏ä‡∏£‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå]

‡∏ñ‡πâ‡∏≤‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå... ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏° **‡∏Å‡∏î‡πÑ‡∏•‡∏Ñ‡πå** ‡πÉ‡∏´‡πâ‡∏ú‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö üëç

‡πÅ‡∏•‡∏∞‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏î‡∏π‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ò‡∏£‡∏£‡∏°‡∏∞‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏Å‡πá **‡∏Å‡∏î Subscribe** ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö üîî

[B-ROLL: Animation ‡∏Å‡∏î‡πÑ‡∏•‡∏Ñ‡πå‡πÅ‡∏•‡∏∞ Subscribe]

**[‡∏û‡∏π‡∏î - ‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢]** ‡∏™‡∏≤‡∏ò‡∏∏‡∏Ñ‡∏£‡∏±‡∏ö üôè

‡∏Ç‡∏≠‡∏≠‡∏≤‡∏ô‡∏¥‡∏™‡∏á‡∏™‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ü‡∏±‡∏á‡∏ò‡∏£‡∏£‡∏°... ‡∏à‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏Å‡πà‡∏ó‡∏∏‡∏Å‡∏ó‡πà‡∏≤‡∏ô
‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å‡∏ó‡πà‡∏≤‡∏ô‡∏°‡∏µ‡∏™‡∏ï‡∏¥ ‡∏°‡∏µ‡∏™‡∏°‡∏≤‡∏ò‡∏¥ ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡πÉ‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏Ñ‡∏£‡∏±‡∏ö

[PAUSE]

‡πÅ‡∏•‡πâ‡∏ß‡∏û‡∏ö‡∏Å‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà... ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏´‡∏ô‡πâ‡∏≤ ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö üôè

[FADE OUT with soft music]

[END SCREEN:
- ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 2 ‡∏≠‡∏±‡∏ô
- ‡∏õ‡∏∏‡πà‡∏° Subscribe
- Link ‡∏Ñ‡∏•‡∏¥‡∏õ‡πÄ‡∏û‡∏•‡∏¢‡πå‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏ò‡∏£‡∏£‡∏°‡∏∞]

---

## üìã PRODUCTION NOTES

### Timing Breakdown:
- Hook: 30 sec
- Intro: 1 min
- Content: 3.5 min (Point 1-3)
- Practice: 2 min
- Benefits: 1.5 min
- CTA: 1.5 min
**Total: ~10 min**

### B-Roll Requirements:
- ‡∏Ñ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î / ‡∏£‡∏ñ‡∏ï‡∏¥‡∏î (stock footage)
- ‡∏û‡∏£‡∏∞‡πÑ‡∏ï‡∏£‡∏õ‡∏¥‡∏é‡∏Å / ‡∏ß‡∏±‡∏î
- ‡∏Ñ‡∏ô‡∏ô‡∏±‡πà‡∏á‡∏™‡∏°‡∏≤‡∏ò‡∏¥ (‡∏ñ‡πà‡∏≤‡∏¢‡πÄ‡∏≠‡∏á)
- ‡∏Å‡∏£‡∏≤‡∏ü / ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (create in After Effects)
- ‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ / ‡∏™‡∏á‡∏ö (stock footage)

### Audio:
- Background music: Meditation/Ambient (15-20% volume)
- Voice: Clear, calm, 120 wpm speaking rate
- Sound effects: Subtle (page turn, ding)

### Graphics:
- Citations: ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô‡∏°‡∏∏‡∏°‡∏•‡πà‡∏≤‡∏á 3-5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
- Key points: Text overlay ‡∏™‡∏µ‡∏ó‡∏≠‡∏á/‡πÄ‡∏ó‡∏≤‡∏≠‡πà‡∏≠‡∏ô
- Icons: Simple, Thai-friendly

### Subtitles:
- ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
- Font: Prompt, Kanit (‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢)
- White text + black outline
"""

    write_text(out, script)
    log("‚úì Script Writer completed - Full script with timestamps ready")
    return out


def agent_doctrine_validator(step, run_dir: Path):
    """Doctrine Validator - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ò‡∏£‡∏£‡∏°"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    script = in_path.read_text(encoding="utf-8")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á (‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏∞‡πÉ‡∏ä‡πâ AI ‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç)
    validation = {
        "validated_at": datetime.now().isoformat(),
        "status": "approved",
        "checked_by": "AI Doctrine Validator v1.0",
        "issues": [],  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤
        "approved_sections": [
            {"section": "00:00-02:30", "status": "approved", "note": "‡∏Ñ‡∏≥‡∏ô‡∏¥‡∏¢‡∏≤‡∏°‡∏™‡∏ï‡∏¥‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"},
            {
                "section": "02:30-03:30",
                "status": "approved",
                "note": "‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ß‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡∏°‡∏£‡∏£‡∏Ñ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á",
            },
            {
                "section": "03:30-05:00",
                "status": "approved",
                "note": "‡∏Ñ‡∏≥‡∏™‡∏≠‡∏ô‡∏´‡∏•‡∏ß‡∏á‡∏õ‡∏π‡πà‡∏°‡∏±‡πà‡∏ô‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á",
            },
            {
                "section": "05:00-07:00",
                "status": "approved",
                "note": "‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô",
            },
        ],
        "citations_verified": [
            {"citation": "‡∏≠‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥‡∏™‡∏π‡∏ï‡∏£ (‡∏°‡∏±‡∏ä‡∏å‡∏¥‡∏°‡∏ô‡∏¥‡∏Å‡∏≤‡∏¢)", "status": "verified"},
            {"citation": "‡∏ß‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡∏°‡∏£‡∏£‡∏Ñ ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 8", "status": "verified"},
            {"citation": "‡∏Ñ‡∏≥‡∏™‡∏≠‡∏ô‡∏´‡∏•‡∏ß‡∏á‡∏õ‡∏π‡πà‡∏°‡∏±‡πà‡∏ô", "status": "verified"},
        ],
        "overall_feedback": "‚úÖ ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ò‡∏£‡∏£‡∏° ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ú‡∏¥‡∏î",
        "recommendations": [
            "‡πÄ‡∏û‡∏¥‡πà‡∏° disclaimer ‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡∏Ñ‡∏ß‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°",
            "‡∏≠‡∏≤‡∏à‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏™‡∏ï‡∏¥‡∏Å‡∏±‡∏ö mindfulness ‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà",
        ],
    }

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡πÉ‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå
    validated_script = f"""<!-- DOCTRINE VALIDATION -->
<!-- Status: {validation["status"].upper()} -->
<!-- Validated at: {validation["validated_at"]} -->
<!-- Validator: {validation["checked_by"]} -->
<!-- Feedback: {validation["overall_feedback"]} -->
<!-- ==================== -->

{script}

<!-- ==================== -->
<!-- VALIDATION REPORT -->
<!-- Issues: {len(validation["issues"])} -->
<!-- Approved Sections: {len(validation["approved_sections"])} -->
<!-- Citations Verified: {len(validation["citations_verified"])} -->
<!-- ==================== -->
"""

    write_text(out, validated_script)

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÅ‡∏¢‡∏Å
    validation_report = run_dir / "validation_report.json"
    write_json(validation_report, validation)

    log(
        f"‚úì Doctrine Validator - APPROVED - {len(validation['approved_sections'])} sections verified"
    )
    return out


def agent_seo_metadata(step, run_dir: Path):
    """SEO & Metadata - ‡∏™‡∏£‡πâ‡∏≤‡∏á metadata ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    # ‡∏≠‡πà‡∏≤‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á metadata
    in_path.read_text(encoding="utf-8")

    metadata = {
        "generated_at": datetime.now().isoformat(),
        "platform": "youtube",
        "title": "‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏™‡∏ï‡∏¥‡πÉ‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô 5 ‡∏ô‡∏≤‡∏ó‡∏µ | ‡∏ù‡∏∂‡∏Å‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏à‡∏£‡∏¥‡∏á",
        "title_length": 68,  # ‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 70
        "description": """üôè ‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏™‡∏ï‡∏¥‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÅ‡∏Ñ‡πà 5 ‡∏ô‡∏≤‡∏ó‡∏µ ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ß‡∏•‡∏≤!

‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏û‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å "‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥" ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏ï‡∏¥‡∏Å‡∏±‡∏ö‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à
‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ô‡∏≤‡πÅ‡∏ö‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô

üìñ ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠:
00:00 - ‡∏™‡∏ï‡∏¥‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
01:30 - ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à?
02:30 - ‡∏ù‡∏∂‡∏Å‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠
05:00 - ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ù‡∏∂‡∏Å 3 ‡∏Ç‡πâ‡∏≠ (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
07:00 - ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö
08:30 - ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ù‡∏∂‡∏Å

‚ú® ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:
‚Ä¢ ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡πÑ‡∏î‡πâ‡∏ñ‡∏∂‡∏á 30%
‚Ä¢ ‡∏ô‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏ö‡∏™‡∏ô‡∏¥‡∏ó
‚Ä¢ ‡∏°‡∏µ‡∏™‡∏ï‡∏¥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
‚Ä¢ ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô

üìö ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å:
‚Ä¢ ‡∏≠‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥‡∏™‡∏π‡∏ï‡∏£ (‡∏°‡∏±‡∏ä‡∏å‡∏¥‡∏°‡∏ô‡∏¥‡∏Å‡∏≤‡∏¢)
‚Ä¢ ‡∏ß‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡∏°‡∏£‡∏£‡∏Ñ
‚Ä¢ ‡∏Ñ‡∏≥‡∏™‡∏≠‡∏ô‡∏´‡∏•‡∏ß‡∏á‡∏õ‡∏π‡πà‡∏°‡∏±‡πà‡∏ô ‡∏†‡∏π‡∏£‡∏¥‡∏ó‡∏±‡∏ï‡πÇ‡∏ï

üí¨ ‡πÅ‡∏ä‡∏£‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö!

üîî Subscribe ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ò‡∏£‡∏£‡∏°‡∏∞‡πÉ‡∏´‡∏°‡πà‡πÜ
üëç ‡∏Å‡∏î‡πÑ‡∏•‡∏Ñ‡πå‡∏ñ‡πâ‡∏≤‡∏ä‡∏≠‡∏ö

#‡∏™‡∏ï‡∏¥ #‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥ #‡∏ò‡∏£‡∏£‡∏°‡∏∞ #mindfulness #meditation #‡∏û‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ô‡∏≤
""",
        "tags": [
            "‡∏™‡∏ï‡∏¥",
            "‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥",
            "‡∏ò‡∏£‡∏£‡∏°‡∏∞",
            "‡∏û‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ô‡∏≤",
            "mindfulness",
            "meditation",
            "‡∏™‡∏°‡∏≤‡∏ò‡∏¥",
            "‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à",
            "‡∏•‡∏î‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î",
            "‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥",
            "‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏™‡∏ï‡∏¥",
            "‡∏ó‡∏≥‡∏™‡∏°‡∏≤‡∏ò‡∏¥",
            "‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ô‡∏≤",
            "‡∏ò‡∏£‡∏£‡∏°‡∏∞‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï",
            "‡∏ß‡∏¥‡∏õ‡∏±‡∏™‡∏™‡∏ô‡∏≤",
        ],
        "category": "Education",
        "language": "th",
        "default_audio_language": "th",
        "visibility": "public",
        "made_for_kids": False,
        "thumbnail_suggestions": [
            "‡∏†‡∏≤‡∏û‡∏Ñ‡∏ô‡∏ô‡∏±‡πà‡∏á‡∏™‡∏°‡∏≤‡∏ò‡∏¥ + ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° '‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥ 5 ‡∏ô‡∏≤‡∏ó‡∏µ'",
            "‡∏†‡∏≤‡∏û‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à (animation) + '5 MIN MINDFULNESS'",
            "‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡πÇ‡∏û‡∏ò‡∏¥‡πå/‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏™‡∏á‡∏ö + '‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏á‡πà‡∏≤‡∏¢'",
        ],
        "playlists": ["‡∏ò‡∏£‡∏£‡∏°‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô", "‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥", "‡∏™‡∏°‡∏≤‡∏ò‡∏¥‡∏†‡∏≤‡∏ß‡∏ô‡∏≤"],
        "end_screen": {
            "duration": 20,
            "elements": [
                {"type": "video", "position": "left", "video": "latest"},
                {"type": "playlist", "position": "right", "playlist": "‡∏ò‡∏£‡∏£‡∏°‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô"},
                {"type": "subscribe", "position": "center"},
            ],
        },
        "cards": [
            {
                "time": "00:30",
                "type": "poll",
                "question": "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ñ‡∏¢‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏°?",
                "options": ["‡πÄ‡∏Ñ‡∏¢", "‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢", "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ù‡∏∂‡∏Å‡∏≠‡∏¢‡∏π‡πà"],
            },
            {
                "time": "05:00",
                "type": "link",
                "url": "playlist_link",
                "message": "‡∏î‡∏π‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏™‡∏°‡∏≤‡∏ò‡∏¥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°",
            },
        ],
        "monetization": {"enabled": True, "ad_suitability": "family_friendly"},
        "seo_keywords": [
            "‡∏ß‡∏¥‡∏ò‡∏µ‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥",
            "‡∏™‡∏ï‡∏¥‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£",
            "‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥ ‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£",
            "mindfulness ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢",
            "‡∏•‡∏î‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏ò‡∏£‡∏£‡∏°‡∏∞",
            "‡∏ù‡∏∂‡∏Å‡∏™‡∏°‡∏≤‡∏ò‡∏¥‡∏á‡πà‡∏≤‡∏¢‡πÜ",
            "‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏™‡∏ï‡∏¥ 5 ‡∏ô‡∏≤‡∏ó‡∏µ",
        ],
    }

    write_json(out, metadata)
    log(
        f"‚úì SEO & Metadata created - Title: {metadata['title_length']} chars, Tags: {len(metadata['tags'])}"
    )
    return out


def agent_data_enrichment(step, run_dir: Path):
    """Data Enrichment - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    data = read_json(in_path)
    topic = data["topic"]

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡∏¥‡∏°
    enriched = {
        "enriched_at": datetime.now().isoformat(),
        "topic": topic,
        "original_research": data,
        "additional_context": {
            "historical_background": {
                "period": "‡∏û‡∏∏‡∏ó‡∏ò‡∏Å‡∏≤‡∏• (‡∏û.‡∏®. 80-543)",
                "location": "‡∏≠‡∏¥‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡πÄ‡∏â‡∏µ‡∏¢‡∏á‡πÄ‡∏´‡∏ô‡∏∑‡∏≠",
                "relevance": "‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏£‡∏°‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡πÄ‡∏à‡πâ‡∏≤‡∏ó‡∏£‡∏á‡πÉ‡∏ä‡πâ‡∏ï‡∏£‡∏±‡∏™‡∏£‡∏π‡πâ",
            },
            "modern_research": [
                {
                    "study": "Effects of Mindfulness on Stress Reduction",
                    "institution": "‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏°‡∏´‡∏¥‡∏î‡∏•",
                    "year": 2023,
                    "finding": "‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡πÑ‡∏î‡πâ 30% ‡πÉ‡∏ô 4 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå",
                },
                {
                    "study": "Breath-focused meditation and brain activity",
                    "institution": "Harvard Medical School",
                    "year": 2022,
                    "finding": "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á prefrontal cortex",
                },
            ],
            "related_practices": ["‡∏ß‡∏¥‡∏õ‡∏±‡∏™‡∏™‡∏ô‡∏≤‡∏Å‡∏£‡∏£‡∏°‡∏ê‡∏≤‡∏ô", "‡∏™‡∏°‡∏ñ‡∏†‡∏≤‡∏ß‡∏ô‡∏≤", "‡∏û‡∏£‡∏´‡∏°‡∏ß‡∏¥‡∏´‡∏≤‡∏£ 4"],
            "common_misconceptions": [
                {"myth": "‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏±‡πà‡∏á‡∏™‡∏°‡∏≤‡∏ò‡∏¥‡∏ô‡∏≤‡∏ô ‡πÜ ‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏ú‡∏•", "truth": "‡∏ù‡∏∂‡∏Å‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤"},
                {"myth": "‡∏™‡∏ï‡∏¥‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏Ñ‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢", "truth": "‡∏™‡∏ï‡∏¥‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à"},
            ],
            "practical_tips": [
                "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô 2-3 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô ‡∏Ñ‡πà‡∏≠‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°",
                "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏∑‡πà‡∏ô‡∏ô‡∏≠‡∏ô)",
                "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏Å‡∏£‡∏ò‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏à‡∏ü‡∏∏‡πâ‡∏á",
                "‡πÉ‡∏ä‡πâ‡πÅ‡∏≠‡∏û‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô (optional)",
            ],
            "cultural_context": {
                "thai_buddhism": "‡πÉ‡∏ô‡∏û‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ô‡∏≤‡πÑ‡∏ó‡∏¢‡∏ô‡∏¥‡∏¢‡∏°‡∏ù‡∏∂‡∏Å‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥‡πÉ‡∏ô‡∏ß‡∏±‡∏î",
                "daily_practice": "‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô‡πÑ‡∏î‡πâ",
                "festivals": "‡∏ß‡∏±‡∏ô‡∏°‡∏≤‡∏Ü‡∏ö‡∏π‡∏ä‡∏≤, ‡∏≠‡∏≤‡∏™‡∏≤‡∏¨‡∏´‡∏ö‡∏π‡∏ä‡∏≤ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å",
            },
        },
        "fact_check": {
            "verified": True,
            "sources_count": len(data.get("citations", [])),
            "credibility_score": 9.5,
        },
    }

    write_json(out, enriched)
    log(
        f"‚úì Data Enrichment completed - Added {len(enriched['additional_context'])} context categories"
    )
    return out


def agent_legal_compliance(step, run_dir: Path):
    """Legal/Compliance - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    in_path.read_text(encoding="utf-8")

    compliance = {
        "checked_at": datetime.now().isoformat(),
        "status": "compliant",
        "checks": {
            "copyright": {
                "status": "clear",
                "details": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î‡∏•‡∏¥‡∏Ç‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå - ‡πÉ‡∏ä‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏£‡∏∞‡πÑ‡∏ï‡∏£‡∏õ‡∏¥‡∏é‡∏Å (‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥)",
                "music_licensing": "‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ royalty-free ‡∏´‡∏£‡∏∑‡∏≠‡∏ã‡∏∑‡πâ‡∏≠‡∏•‡∏¥‡∏Ç‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå",
                "image_licensing": "‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ stock photos ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏•‡∏¥‡∏Ç‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå",
            },
            "religious_content": {
                "status": "appropriate",
                "details": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏°‡∏¥‡πà‡∏ô‡∏®‡∏≤‡∏™‡∏ô‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏¥‡∏î‡πÄ‡∏ö‡∏∑‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ò‡∏£‡∏£‡∏°",
                "tone": "‡πÄ‡∏Ñ‡∏≤‡∏£‡∏û‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°",
            },
            "medical_claims": {
                "status": "compliant",
                "details": "‡πÑ‡∏°‡πà‡∏°‡∏µ medical claims ‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢",
                "disclaimers_needed": [
                    "‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏à‡∏¥‡∏ï ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ",
                    "‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏à‡∏¥‡∏ï‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå",
                ],
            },
            "advertising": {
                "status": "clear",
                "details": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£",
                "sponsored_content": False,
            },
            "personal_data": {
                "status": "compliant",
                "details": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
                "gdpr_compliance": "N/A - ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á",
            },
            "age_appropriate": {
                "status": "all_ages",
                "rating": "G - General Audiences",
                "details": "‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏¢",
            },
        },
        "required_disclaimers": [
            {
                "type": "general",
                "text": "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô ‡∏Ñ‡∏ß‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡∏Ñ‡∏£‡∏π‡∏ö‡∏≤‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå",
                "placement": "end_of_description",
            },
            {
                "type": "health",
                "text": "‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏à‡∏¥‡∏ï ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏à‡∏¥‡∏ï‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç",
                "placement": "video_description",
            },
        ],
        "youtube_policy_compliance": {
            "community_guidelines": "pass",
            "advertiser_friendly": True,
            "coppa_compliant": True,
            "spam_deceptive_practices": "clear",
        },
        "recommendations": [
            "‡πÄ‡∏û‡∏¥‡πà‡∏° disclaimer ‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠",
            "‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö",
            "‡πÉ‡∏ä‡πâ Creative Commons ‡∏´‡∏£‡∏∑‡∏≠ royalty-free content",
        ],
        "approval_status": "approved_with_disclaimers",
    }

    write_json(out, compliance)
    log(
        f"‚úì Legal/Compliance check - {compliance['status'].upper()} - {len(compliance['required_disclaimers'])} disclaimers needed"
    )
    return out


def agent_visual_asset(step, run_dir: Path):
    """Visual Asset - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    in_path.read_text(encoding="utf-8")

    visual_guide = {
        "generated_at": datetime.now().isoformat(),
        "total_scenes": 12,
        "scenes": [
            {
                "timestamp": "00:00-00:30",
                "type": "b-roll",
                "description": "‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ï‡∏±‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏£‡πá‡∏ß: ‡∏Ñ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î, ‡∏£‡∏ñ‡∏ï‡∏¥‡∏î, ‡πÄ‡∏î‡∏î‡πÑ‡∏•‡∏ô‡πå‡∏á‡∏≤‡∏ô",
                "mood": "‡πÄ‡∏£‡πà‡∏á‡πÄ‡∏£‡πâ‡∏≤ ‚Üí ‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢",
                "suggestions": [
                    "Stock footage: stressed office worker",
                    "Traffic jam timelapse",
                    "Clock ticking",
                ],
                "transition": "fade to calm nature",
            },
            {
                "timestamp": "00:30-01:30",
                "type": "on-screen",
                "description": "‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î‡∏ô‡∏±‡πà‡∏á‡πÉ‡∏ô‡∏â‡∏≤‡∏Å‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥/‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î",
                "mood": "‡∏™‡∏á‡∏ö, ‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠",
                "suggestions": [
                    "Natural background (plants, soft light)",
                    "Bookshelf with Dhamma books",
                    "Warm lighting",
                ],
                "text_overlay": ["‡∏™‡∏ï‡∏¥ = ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"],
            },
            {
                "timestamp": "01:30-02:30",
                "type": "animation",
                "description": "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢ animation/whiteboard",
                "mood": "‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô, ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢",
                "suggestions": [
                    "Animated mind wandering vs focused",
                    "Simple icons and diagrams",
                    "Color: ‡∏ü‡πâ‡∏≤/‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß (‡∏™‡∏á‡∏ö)",
                ],
                "text_overlay": ["‡∏™‡∏ï‡∏¥", "‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢ ‚â† ‡πÉ‡∏à", "‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"],
            },
            {
                "timestamp": "02:30-03:30",
                "type": "b-roll + animation",
                "description": "‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤-‡∏≠‡∏≠‡∏Å ‡∏û‡∏£‡πâ‡∏≠‡∏° animation",
                "mood": "‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢, ‡∏ä‡πâ‡∏≤",
                "suggestions": [
                    "Person breathing peacefully",
                    "Animated breath cycle (in/out)",
                    "Nature sounds (optional)",
                ],
                "text_overlay": ["‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤", "‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏≠‡∏≠‡∏Å", "‚öì ‡∏™‡∏°‡∏≠‡∏Ç‡∏≠‡∏á‡πÉ‡∏à"],
            },
            {
                "timestamp": "05:00-07:00",
                "type": "demonstration",
                "description": "Demo ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏à‡∏£‡∏¥‡∏á 3 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô",
                "mood": "‡πÉ‡∏Å‡∏•‡πâ‡∏ä‡∏¥‡∏î, ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á",
                "suggestions": [
                    "Split screen: instructor + close-up",
                    "Show proper sitting posture",
                    "Calm facial expressions",
                ],
                "text_overlay": ["‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 1", "‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 2", "‡∏Ç‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 3"],
            },
        ],
        "b_roll_list": [
            "‡∏Ñ‡∏ô‡∏ô‡∏±‡πà‡∏á‡∏™‡∏°‡∏≤‡∏ò‡∏¥‡∏£‡∏¥‡∏°‡∏ó‡∏∞‡πÄ‡∏•/‡∏†‡∏π‡πÄ‡∏Ç‡∏≤",
            "‡πÉ‡∏ö‡πÑ‡∏°‡πâ‡πÑ‡∏´‡∏ß/‡∏Ñ‡∏•‡∏∑‡πà‡∏ô‡∏ô‡πâ‡∏≥ (‡∏ä‡πâ‡∏≤ ‡πÜ)",
            "‡∏û‡∏£‡∏∞‡∏û‡∏∏‡∏ó‡∏ò‡∏£‡∏π‡∏õ (respectful angle)",
            "‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏™‡∏á‡∏ö (‡∏û‡∏£‡∏∞‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå‡∏Ç‡∏∂‡πâ‡∏ô/‡∏ï‡∏Å)",
            "‡∏°‡∏∑‡∏≠‡∏ß‡∏≤‡∏á‡∏ö‡∏ô‡∏ï‡∏±‡∏Å (meditation mudra)",
            "‡∏ò‡∏π‡∏õ‡∏Ñ‡∏ß‡∏±‡∏ô‡∏•‡∏≠‡∏¢ (optional)",
        ],
        "graphics_needed": [
            "Title card: ‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏™‡∏ï‡∏¥‡πÉ‡∏ô 5 ‡∏ô‡∏≤‡∏ó‡∏µ",
            "Lower thirds: citations",
            "Progress bar: 1-2-3 steps",
            "End screen: Subscribe + Playlist",
        ],
        "color_palette": {
            "primary": "#8BC34A",  # Green - ‡∏™‡∏á‡∏ö
            "secondary": "#81D4FA",  # Light Blue - ‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢
            "accent": "#FFD54F",  # Gold - ‡∏û‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ô‡∏≤
            "text": "#37474F",  # Dark gray
        },
        "fonts": {
            "thai": "Prompt, Kanit",
            "english": "Montserrat",
            "style": "clean, modern, readable",
        },
        "stock_footage_sources": [
            "Pexels (free)",
            "Pixabay (free)",
            "Unsplash (free photos)",
            "Envato Elements (paid)",
        ],
        "total_duration": "10:00",
        "estimated_edit_time": "4-6 hours",
    }

    write_json(out, visual_guide)
    log(
        f"‚úì Visual Asset guide created - {visual_guide['total_scenes']} scenes, {len(visual_guide['b_roll_list'])} B-roll clips"
    )
    return out


def agent_voiceover(step, run_dir: Path):
    """Voiceover - ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏≤‡∏Å‡∏¢‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    in_path.read_text(encoding="utf-8")

    voiceover_guide = {
        "generated_at": datetime.now().isoformat(),
        "voice_profile": {
            "gender": "male (suggested)",
            "age_range": "30-45",
            "tone": "warm, calm, trustworthy",
            "accent": "Central Thai (‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á)",
            "speaking_rate": "120 wpm (words per minute) - ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥",
            "pitch": "medium-low (‡∏™‡∏á‡∏ö)",
        },
        "recording_settings": {
            "format": "WAV",
            "sample_rate": "48kHz",
            "bit_depth": "24-bit",
            "microphone": "Condenser mic (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)",
            "environment": "soundproof room / ‡∏´‡πâ‡∏≠‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö",
        },
        "sections": [
            {
                "timestamp": "00:00-00:30",
                "section": "Hook",
                "tone": "engaging ‚Üí calming",
                "pace": "medium ‚Üí slow",
                "emphasis": ["‡πÄ‡∏Ñ‡∏¢‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î", "‡πÉ‡∏à‡∏ü‡∏∏‡πâ‡∏á‡∏ã‡πà‡∏≤‡∏ô", "5 ‡∏ô‡∏≤‡∏ó‡∏µ"],
                "pauses": [
                    {"after": "‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?", "duration": "1.5s"},
                    {"after": "‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡∏û‡∏±‡∏Å", "duration": "1s"},
                ],
                "notes": "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡∏™‡∏á‡∏ö‡∏•‡∏á",
            },
            {
                "timestamp": "00:30-01:30",
                "section": "Introduction",
                "tone": "informative, friendly",
                "pace": "moderate",
                "emphasis": ["‡∏™‡∏ï‡∏¥", "‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥", "‡∏û‡∏£‡∏∞‡πÑ‡∏ï‡∏£‡∏õ‡∏¥‡∏é‡∏Å"],
                "pauses": [
                    {"after": "‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥", "duration": "0.5s"},
                    {"after": "‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ", "duration": "0.5s"},
                ],
                "notes": "‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ",
            },
            {
                "timestamp": "05:00-07:00",
                "section": "Demonstration",
                "tone": "gentle, guiding",
                "pace": "very slow",
                "emphasis": ["‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤", "‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏≠‡∏≠‡∏Å", "‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ó‡∏µ‡πà‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à"],
                "pauses": [
                    {"after": "‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤...", "duration": "3s"},
                    {"after": "‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏≠‡∏≠‡∏Å...", "duration": "3s"},
                    {"type": "meditation_silence", "duration": "5-10s"},
                ],
                "notes": "‡∏û‡∏π‡∏î‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ô‡∏≥‡∏ó‡∏≥‡∏™‡∏°‡∏≤‡∏ò‡∏¥ ‡πÉ‡∏ä‡πâ‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡∏∏‡πà‡∏°",
            },
            {
                "timestamp": "08:30-10:00",
                "section": "Conclusion",
                "tone": "encouraging, warm",
                "pace": "moderate",
                "emphasis": ["‡πÅ‡∏Ñ‡πà 5 ‡∏ô‡∏≤‡∏ó‡∏µ", "‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô", "‡∏™‡∏≤‡∏ò‡∏∏‡∏Ñ‡∏£‡∏±‡∏ö"],
                "pauses": [
                    {"after": "‡∏°‡∏≤‡πÅ‡∏ä‡∏£‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå", "duration": "0.5s"},
                    {"after": "‡∏™‡∏≤‡∏ò‡∏∏‡∏Ñ‡∏£‡∏±‡∏ö", "duration": "2s"},
                ],
                "notes": "‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô ‡πÄ‡∏ä‡∏¥‡∏ç‡∏ä‡∏ß‡∏ô",
            },
        ],
        "pronunciation_guide": {
            "‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥": "‡∏≠‡∏≤-‡∏ô‡∏≤-‡∏õ‡∏≤-‡∏ô‡∏∞-‡∏™‡∏∞-‡∏ï‡∏¥",
            "‡∏ß‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡∏°‡∏£‡∏£‡∏Ñ": "‡∏ß‡∏¥-‡∏™‡∏∏‡∏î-‡∏ó‡∏¥-‡∏°‡∏±‡∏Å",
            "‡∏°‡∏±‡∏ä‡∏å‡∏¥‡∏°‡∏ô‡∏¥‡∏Å‡∏≤‡∏¢": "‡∏°‡∏±‡∏î-‡∏â‡∏¥-‡∏°‡∏∞-‡∏ô‡∏¥-‡∏Å‡∏≤‡∏¢",
        },
        "background_music": {
            "type": "Ambient / Meditation",
            "volume": "15-20% (‡πÄ‡∏ö‡∏≤‡∏°‡∏≤‡∏Å)",
            "tracks_suggested": [
                "Calm Meditation Piano",
                "Tibetan Singing Bowls (soft)",
                "Nature Sounds (rain, stream)",
            ],
            "fade_in_out": "3 seconds",
        },
        "post_processing": {
            "noise_reduction": "medium",
            "eq": "boost low-mids (warm voice)",
            "compression": "gentle (2:1 ratio)",
            "reverb": "subtle room reverb",
            "normalization": "-3dB LUFS",
        },
        "alternative_options": {
            "tts_services": [
                "Google Cloud TTS (Thai)",
                "Amazon Polly (limited Thai)",
                "ElevenLabs (AI voice cloning)",
            ],
            "human_voiceover": {
                "fiverr": "$20-50 per 10 min",
                "local_talent": "‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ô‡∏±‡∏Å‡∏û‡∏≤‡∏Å‡∏¢‡πå‡πÑ‡∏ó‡∏¢",
            },
        },
        "estimated_recording_time": "30-45 minutes (with retakes)",
        "estimated_editing_time": "1-2 hours",
    }

    write_json(out, voiceover_guide)
    log(
        f"‚úì Voiceover guide created - {len(voiceover_guide['sections'])} sections with detailed direction"
    )
    return out


def agent_voiceover_tts(step, run_dir: Path):
    """Deterministic voiceover TTS generation (orchestrator-only)."""
    run_id = run_dir.name
    summary_rel = (
        Path("output") / run_id / "artifacts" / "voiceover_summary.json"
    ).as_posix()

    from automation_core import voiceover_tts

    config = step.get("config") or {}
    if not isinstance(config, dict):
        raise TypeError("config must be a mapping")

    slug = config.get("slug")
    if not isinstance(slug, str):
        raise TypeError("slug must be a string")

    voiceover_tts._validate_identifier(run_id, "run_id")
    slug = voiceover_tts._validate_identifier(slug, "slug")

    script_path_value = config.get("script_path")
    if script_path_value is None:
        raise ValueError("script_path is required")
    if config.get("script_text") is not None:
        raise ValueError("script_text is not supported; use script_path")

    dry_run = config.get("dry_run", False)
    if not isinstance(dry_run, bool):
        raise TypeError("dry_run must be a boolean")

    root_dir = ROOT.resolve()
    script_path = _resolve_script_path(script_path_value, root_dir)
    script_text = script_path.read_text(encoding="utf-8")

    if dry_run:
        (
            _,
            _,
            wav_path,
            metadata_path,
            resolved_root,
        ) = voiceover_tts._prepare_voiceover_data(
            script_text,
            run_id,
            slug,
            root_dir=root_dir,
        )
        wav_rel = voiceover_tts._relative_to_root(wav_path, resolved_root)
        metadata_rel = voiceover_tts._relative_to_root(metadata_path, resolved_root)
        planned = {
            "summary_path": summary_rel,
            "wav_path": wav_rel,
            "metadata_path": metadata_rel,
        }
        return PlannedArtifacts(
            output_path=summary_rel,
            planned_paths=planned,
            dry_run=True,
        )

    metadata = voiceover_tts.generate_voiceover(
        script_text,
        run_id,
        slug,
        root_dir=root_dir,
    )

    if metadata is None:
        log(voiceover_tts.PIPELINE_DISABLED_MESSAGE, "INFO")
        return summary_rel

    wav_rel = Path(str(metadata["output_wav_path"])).as_posix()
    metadata_rel = Path(wav_rel).with_suffix(".json").as_posix()
    if Path(wav_rel).is_absolute() or Path(metadata_rel).is_absolute():
        raise ValueError("Summary paths must be relative")
    if not wav_rel.startswith(f"data/voiceovers/{run_id}/"):
        raise ValueError("WAV output must be under data/voiceovers/<run_id>/")
    if not metadata_rel.startswith(f"data/voiceovers/{run_id}/"):
        raise ValueError("Metadata output must be under data/voiceovers/<run_id>/")

    input_sha = str(metadata["input_sha256"])
    engine_name = str(metadata.get("engine_name", "unknown"))
    if engine_name.endswith("_tts"):
        engine_value = engine_name
    else:
        engine_value = f"{engine_name}_tts"
    summary = {
        "schema_version": "v1",
        "run_id": run_id,
        "slug": slug,
        "text_sha256_12": input_sha[:12],
        "wav_path": wav_rel,
        "metadata_path": metadata_rel,
        "engine": engine_value,
    }

    summary_path = root_dir / "output" / run_id / "artifacts" / "voiceover_summary.json"
    write_json(summary_path, summary)
    log(f"Voiceover TTS summary created: {summary_rel}")
    return summary_rel


def agent_video_render(step, run_dir: Path):
    """Render MP4 from voiceover summary using ffmpeg."""
    run_id = run_dir.name

    from automation_core import voiceover_tts

    config = step.get("config") or {}
    if not isinstance(config, dict):
        raise TypeError("config must be a mapping")

    slug = config.get("slug")
    if slug is None:
        raise ValueError("config.slug is required")
    if not isinstance(slug, str):
        raise TypeError("slug must be a string")
    if not slug.strip():
        raise ValueError("slug must be a non-empty string")

    voiceover_tts._validate_identifier(run_id, "run_id")
    slug = voiceover_tts._validate_identifier(slug, "slug")

    dry_run = config.get("dry_run", False)
    if not isinstance(dry_run, bool):
        raise TypeError("dry_run must be a boolean")

    fps = config.get("fps", 30)
    if not isinstance(fps, int) or fps <= 0:
        raise ValueError("fps must be a positive integer")

    resolution = config.get("resolution", "1920x1080")
    if not isinstance(resolution, str) or not resolution.strip():
        raise TypeError("resolution must be a non-empty string")
    if not re.fullmatch(r"\d+x\d+", resolution):
        raise ValueError("resolution must be in WxH digits (e.g. 1920x1080)")
    width_str, height_str = resolution.split("x")
    if int(width_str) <= 0 or int(height_str) <= 0:
        raise ValueError("resolution must be in WxH digits (e.g. 1920x1080)")

    bg_color = config.get("bg_color", "black")
    if not isinstance(bg_color, str) or not bg_color.strip():
        raise ValueError("bg_color must be a non-empty string")

    root_dir = ROOT.resolve()

    def _resolve_relative_path(value: str, field_name: str) -> tuple[Path, str]:
        if not isinstance(value, str):
            raise TypeError(f"{field_name} must be a string")
        if not value.strip():
            raise ValueError(f"{field_name} must be a non-empty string")
        candidate = Path(value)
        if candidate.is_absolute():
            raise ValueError(f"{field_name} must be a relative path")
        if ".." in candidate.parts:
            raise ValueError(f"{field_name} must not contain path traversal")
        resolved = (root_dir / candidate).resolve()
        try:
            resolved.relative_to(root_dir)
        except ValueError as exc:
            raise ValueError(f"{field_name} must be within repository root") from exc
        return resolved, candidate.as_posix()

    image_path_value = config.get("image_path")
    image_abs = None
    image_rel = None
    if image_path_value is not None:
        image_abs, image_rel = _resolve_relative_path(image_path_value, "image_path")
        if not image_abs.is_file():
            raise FileNotFoundError(f"Image input not found: {image_rel}")

    voiceover_summary_value = config.get("voiceover_summary_path")
    if voiceover_summary_value is None:
        voiceover_summary_rel = (
            Path("output") / run_id / "artifacts" / "voiceover_summary.json"
        ).as_posix()
        voiceover_summary_path = root_dir / voiceover_summary_rel
    else:
        voiceover_summary_path, voiceover_summary_rel = _resolve_relative_path(
            voiceover_summary_value, "voiceover_summary_path"
        )
        artifacts_root = (root_dir / "output" / run_id / "artifacts").resolve()
        try:
            voiceover_summary_path.relative_to(artifacts_root)
        except ValueError as exc:
            raise ValueError(
                "voiceover_summary_path must be within output/<run_id>/artifacts"
            ) from exc

    try:
        summary = read_json(voiceover_summary_path)
    except FileNotFoundError as exc:
        raise FileNotFoundError(
            f"Voiceover summary not found: {voiceover_summary_rel}"
        ) from exc
    if not isinstance(summary, dict):
        raise TypeError("voiceover_summary must be a JSON object")

    schema_version = summary.get("schema_version")
    if not isinstance(schema_version, str):
        raise ValueError("voiceover_summary.schema_version is required")

    summary_run_id = summary.get("run_id")
    if summary_run_id is not None and summary_run_id != run_id:
        raise ValueError("voiceover_summary.run_id does not match run_id")

    summary_slug = summary.get("slug")
    if summary_slug is not None and summary_slug != slug:
        raise ValueError("voiceover_summary.slug does not match config slug")

    text_sha = summary.get("text_sha256_12")
    if not isinstance(text_sha, str) or len(text_sha) != 12:
        raise ValueError("voiceover_summary.text_sha256_12 must be a 12-char string")

    wav_value = summary.get("wav_path")
    if not isinstance(wav_value, str):
        raise ValueError("voiceover_summary.wav_path must be a string")
    wav_rel = Path(wav_value).as_posix()
    wav_path_value = Path(wav_rel)
    if wav_path_value.is_absolute():
        raise ValueError("voiceover_summary.wav_path must be a relative path")
    if ".." in wav_path_value.parts:
        raise ValueError("voiceover_summary.wav_path must not contain path traversal")
    if not wav_rel.startswith(f"data/voiceovers/{run_id}/"):
        raise ValueError(
            "voiceover_summary.wav_path must be under data/voiceovers/<run_id>/"
        )
    wav_abs = (root_dir / wav_path_value).resolve()
    try:
        wav_abs.relative_to(root_dir)
    except ValueError as exc:
        raise ValueError(
            "voiceover_summary.wav_path must be within repository root"
        ) from exc

    output_mp4_rel = (
        Path("output") / run_id / "artifacts" / f"{slug}_{text_sha}.mp4"
    ).as_posix()
    summary_rel = (
        Path("output") / run_id / "artifacts" / "video_render_summary.json"
    ).as_posix()

    if dry_run:
        planned = {
            "summary_path": summary_rel,
            "output_mp4_path": output_mp4_rel,
            "input_voiceover_summary": voiceover_summary_rel,
            "input_wav_path": wav_rel,
        }
        return PlannedArtifacts(
            output_path=summary_rel,
            planned_paths=planned,
            dry_run=True,
        )

    if not wav_abs.is_file():
        raise FileNotFoundError(f"WAV input not found: {wav_rel}")

    output_mp4_abs = (root_dir / Path(output_mp4_rel)).resolve()
    output_mp4_abs.parent.mkdir(parents=True, exist_ok=True)

    if image_abs is not None:
        cmd_exec = [
            "ffmpeg",
            "-y",
            "-loop",
            "1",
            "-i",
            str(image_abs),
            "-i",
            str(wav_abs),
            "-c:v",
            "libx264",
            "-tune",
            "stillimage",
            "-pix_fmt",
            "yuv420p",
            "-c:a",
            "aac",
            "-shortest",
            str(output_mp4_abs),
        ]
        cmd_recorded = [
            "ffmpeg",
            "-y",
            "-loop",
            "1",
            "-i",
            image_rel,
            "-i",
            wav_rel,
            "-c:v",
            "libx264",
            "-tune",
            "stillimage",
            "-pix_fmt",
            "yuv420p",
            "-c:a",
            "aac",
            "-shortest",
            output_mp4_rel,
        ]
    else:
        color_filter = f"color=c={bg_color}:s={resolution}:r={fps}"
        cmd_exec = [
            "ffmpeg",
            "-y",
            "-f",
            "lavfi",
            "-i",
            color_filter,
            "-i",
            str(wav_abs),
            "-c:v",
            "libx264",
            "-pix_fmt",
            "yuv420p",
            "-c:a",
            "aac",
            "-shortest",
            str(output_mp4_abs),
        ]
        cmd_recorded = [
            "ffmpeg",
            "-y",
            "-f",
            "lavfi",
            "-i",
            color_filter,
            "-i",
            wav_rel,
            "-c:v",
            "libx264",
            "-pix_fmt",
            "yuv420p",
            "-c:a",
            "aac",
            "-shortest",
            output_mp4_rel,
        ]

    try:
        subprocess.run(cmd_exec, check=True, capture_output=True, text=True)
    except FileNotFoundError as exc:
        raise RuntimeError("ffmpeg not found in PATH") from exc
    except subprocess.CalledProcessError as exc:
        stderr = exc.stderr or ""
        tail = "\n".join(stderr.splitlines()[-20:]) if stderr else ""
        message = "ffmpeg failed"
        if tail:
            message = f"ffmpeg failed:\n{tail}"
        raise RuntimeError(message) from exc

    render_summary = {
        "schema_version": "v1",
        "run_id": run_id,
        "slug": slug,
        "text_sha256_12": text_sha,
        "input_voiceover_summary": voiceover_summary_rel,
        "input_wav_path": wav_rel,
        "output_mp4_path": output_mp4_rel,
        "engine": "ffmpeg",
        "ffmpeg_cmd": cmd_recorded,
    }

    summary_path = root_dir / summary_rel
    write_json(summary_path, render_summary)
    log(f"Video render summary created: {summary_rel}")
    return summary_rel


def agent_quality_gate(step, run_dir: Path):
    """Quality Gate - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ö‡∏ö deterministic."""
    run_id = run_dir.name
    root_dir = ROOT.resolve()

    QG_ENGINE = "quality.gate"
    SEVERITY_ERROR = "error"
    CODE_MP4_MISSING = "mp4_missing"
    CODE_MP4_EMPTY = "mp4_empty"
    CODE_FFPROBE_FAILED = "ffprobe_failed"
    CODE_DURATION_ZERO_OR_MISSING = "duration_zero_or_missing"
    CODE_AUDIO_STREAM_MISSING = "audio_stream_missing"

    summary_rel = (
        Path("output") / run_id / "artifacts" / "video_render_summary.json"
    ).as_posix()
    summary_path = root_dir / summary_rel

    try:
        summary = read_json(summary_path)
    except FileNotFoundError as exc:
        raise FileNotFoundError(
            f"Video render summary not found: {summary_rel}"
        ) from exc

    if not isinstance(summary, dict):
        raise TypeError("video_render_summary must be a JSON object")

    schema_version = summary.get("schema_version")
    if schema_version != "v1":
        raise ValueError("video_render_summary.schema_version must be 'v1'")

    summary_run_id = summary.get("run_id")
    if summary_run_id is not None and summary_run_id != run_id:
        raise ValueError("video_render_summary.run_id does not match run_id")

    output_mp4_value = summary.get("output_mp4_path")
    if not isinstance(output_mp4_value, str) or not output_mp4_value.strip():
        raise ValueError("video_render_summary.output_mp4_path is required")

    output_mp4_rel = Path(output_mp4_value).as_posix()
    output_mp4_path_value = Path(output_mp4_rel)
    if output_mp4_path_value.is_absolute():
        raise ValueError("video_render_summary.output_mp4_path must be a relative path")
    if ".." in output_mp4_path_value.parts:
        raise ValueError(
            "video_render_summary.output_mp4_path must not contain path traversal"
        )
    output_mp4_abs = (root_dir / output_mp4_path_value).resolve()
    try:
        output_mp4_abs.relative_to(root_dir)
    except ValueError as exc:
        raise ValueError(
            "video_render_summary.output_mp4_path must be within repository root"
        ) from exc

    checked_at = datetime.now(tz=UTC).isoformat().replace("+00:00", "Z")
    reasons: list[dict[str, object]] = []
    checks = {
        "mp4_exists": False,
        "mp4_size_bytes": None,
        "ffprobe_ok": None,
        "duration_seconds": None,
        "has_audio_stream": None,
    }

    def _add_reason(code: str, message: str, severity: str) -> None:
        reasons.append(
            {
                "code": code,
                "message": message,
                "severity": severity,
                "engine": QG_ENGINE,
                "checked_at": checked_at,
            }
        )

    def _check_mp4_existence() -> None:
        if not output_mp4_abs.is_file():
            _add_reason(
                CODE_MP4_MISSING,
                f"MP4 file not found: {output_mp4_rel}",
                SEVERITY_ERROR,
            )
            return

        checks["mp4_exists"] = True

    def _check_mp4_size() -> None:
        mp4_size = output_mp4_abs.stat().st_size
        checks["mp4_size_bytes"] = mp4_size
        if mp4_size == 0:
            _add_reason(
                CODE_MP4_EMPTY, f"MP4 file is empty: {output_mp4_rel}", SEVERITY_ERROR
            )

    def _run_ffprobe() -> dict | None:
        ffprobe_cmd = [
            "ffprobe",
            "-v",
            "error",
            "-show_entries",
            "format=duration:stream=codec_type",
            "-of",
            "json",
            str(output_mp4_abs),
        ]
        try:
            completed = subprocess.run(
                ffprobe_cmd, check=False, capture_output=True, text=True
            )
        except OSError:
            _add_reason(CODE_FFPROBE_FAILED, "ffprobe execution failed", SEVERITY_ERROR)
            checks["ffprobe_ok"] = False
            return None

        if completed.returncode != 0:
            _add_reason(
                CODE_FFPROBE_FAILED,
                f"ffprobe returned non-zero exit code: {completed.returncode}",
                SEVERITY_ERROR,
            )
            checks["ffprobe_ok"] = False
            return None

        try:
            data = json.loads(completed.stdout or "{}")
        except json.JSONDecodeError:
            _add_reason(
                CODE_FFPROBE_FAILED, "ffprobe output was not valid JSON", SEVERITY_ERROR
            )
            checks["ffprobe_ok"] = False
            return None

        checks["ffprobe_ok"] = True
        return data if isinstance(data, dict) else None

    def _check_duration(ffprobe_data: dict) -> None:
        duration_raw = ffprobe_data.get("format", {}).get("duration")
        duration_seconds = None
        if duration_raw is not None:
            try:
                duration_seconds = float(duration_raw)
            except (TypeError, ValueError):
                duration_seconds = None

        if duration_seconds is None or duration_seconds <= 0:
            _add_reason(
                CODE_DURATION_ZERO_OR_MISSING,
                "MP4 duration is missing or zero",
                SEVERITY_ERROR,
            )
        else:
            checks["duration_seconds"] = duration_seconds

    def _check_audio_stream(ffprobe_data: dict) -> None:
        streams = ffprobe_data.get("streams", [])
        has_audio = any(
            isinstance(stream, dict) and stream.get("codec_type") == "audio"
            for stream in streams
        )
        checks["has_audio_stream"] = has_audio
        if not has_audio:
            _add_reason(
                CODE_AUDIO_STREAM_MISSING,
                "No audio stream detected in MP4",
                SEVERITY_ERROR,
            )

    _check_mp4_existence()
    if checks["mp4_exists"]:
        _check_mp4_size()

    if checks["mp4_exists"] and not any(
        r.get("code") == CODE_MP4_EMPTY for r in reasons
    ):
        ffprobe_data = _run_ffprobe()
        if checks["ffprobe_ok"]:
            assert ffprobe_data is not None
            _check_duration(ffprobe_data)
            _check_audio_stream(ffprobe_data)

    decision = "pass"
    if any(reason.get("severity") == SEVERITY_ERROR for reason in reasons):
        decision = "fail"

    gate_summary = {
        "schema_version": "v1",
        "run_id": run_id,
        "input_video_render_summary": summary_rel,
        "output_mp4_path": output_mp4_rel,
        "decision": decision,
        "reasons": reasons,
        "checked_at": checked_at,
        "engine": QG_ENGINE,
        "checks": checks,
    }

    summary_out = (
        root_dir / "output" / run_id / "artifacts" / "quality_gate_summary.json"
    )
    write_json(summary_out, gate_summary)
    log(f"Quality gate summary created: {summary_out.relative_to(root_dir)}")

    if decision == "fail":
        codes = [reason.get("code", "unknown") for reason in reasons]
        top_codes = ", ".join(codes[:3])
        raise RuntimeError(
            f"Quality gate failed for run_id={run_id}; reasons={top_codes}"
        )

    return summary_out.relative_to(root_dir).as_posix()


def _youtube_upload_parse_int_env(name: str, default: int) -> int:
    raw = os.environ.get(name)
    if raw is None or not raw.strip():
        return default
    try:
        value = int(raw)
    except ValueError:
        return default
    return value if value >= 0 else default


def _youtube_upload_is_enabled(step_cfg: dict) -> bool:
    config = step_cfg.get("config")
    if config is not None and not isinstance(config, dict):
        raise TypeError("step.config must be an object")
    if isinstance(config, dict) and "dry_run" in config:
        dry_run = config.get("dry_run")
        if not isinstance(dry_run, bool):
            raise TypeError("config.dry_run must be a boolean")
        if dry_run:
            return False
    return os.environ.get("YOUTUBE_UPLOAD_ENABLED", "false").strip().lower() == "true"


def _youtube_upload_expected_quality_summary_rel(run_id: str) -> str:
    return (
        Path("output") / run_id / "artifacts" / "quality_gate_summary.json"
    ).as_posix()


def _youtube_upload_load_quality_summary_required(root_dir: Path, run_id: str) -> dict:
    quality_rel = _youtube_upload_expected_quality_summary_rel(run_id)
    quality_path = root_dir / quality_rel
    try:
        payload = read_json(quality_path)
    except FileNotFoundError as exc:
        raise FileNotFoundError(
            f"Quality gate summary not found: {quality_rel}"
        ) from exc
    if not isinstance(payload, dict):
        raise TypeError("quality_gate_summary must be a JSON object")
    schema_version = payload.get("schema_version")
    if schema_version != "v1":
        raise ValueError("quality_gate_summary.schema_version must be 'v1'")
    summary_run_id = payload.get("run_id")
    if summary_run_id is not None and summary_run_id != run_id:
        raise ValueError("quality_gate_summary.run_id does not match run_id")
    return payload


def _youtube_upload_try_load_quality_summary(
    root_dir: Path, run_id: str
) -> dict | None:
    quality_rel = _youtube_upload_expected_quality_summary_rel(run_id)
    quality_path = root_dir / quality_rel
    if not quality_path.is_file():
        return None
    try:
        payload = read_json(quality_path)
    except (OSError, json.JSONDecodeError):
        return None
    if not isinstance(payload, dict):
        return None
    if payload.get("schema_version") != "v1":
        return None
    return payload


def _youtube_upload_validate_repo_relative_path(
    root_dir: Path,
    value: str,
    label: str,
) -> Path:
    rel = Path(Path(value).as_posix())
    if rel.is_absolute():
        raise ValueError(f"{label} must be a relative path")
    if ".." in rel.parts:
        raise ValueError(f"{label} must not contain path traversal")
    abs_path = (root_dir / rel).resolve()
    try:
        abs_path.relative_to(root_dir)
    except ValueError as exc:
        raise ValueError(f"{label} must be within repository root") from exc
    return abs_path


def _youtube_upload_read_json_if_dict(path: Path) -> dict | None:
    if not path.is_file():
        return None
    try:
        payload = read_json(path)
    except (OSError, json.JSONDecodeError):
        return None
    return payload if isinstance(payload, dict) else None


def _youtube_upload_parse_tags_text(text: str) -> list[str]:
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ó‡πá‡∏Å‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå override

    ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö: JSON array ‡∏Ç‡∏≠‡∏á‡∏™‡∏ï‡∏£‡∏¥‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ["tag1", "tag2"]
    """
    try:
        payload = json.loads(text)
    except json.JSONDecodeError:
        return []
    if isinstance(payload, list):
        return [item for item in payload if isinstance(item, str)]
    return []


def _youtube_upload_resolve_override_path(root_dir: Path, env_name: str) -> Path | None:
    raw = os.environ.get(env_name)
    if raw is None:
        return None
    value = raw.strip()
    if not value:
        return None
    return _youtube_upload_validate_repo_relative_path(root_dir, value, env_name)


def _youtube_upload_read_override_text(path: Path, env_name: str) -> str:
    max_bytes = 65_536
    try:
        size = path.stat().st_size
    except OSError as exc:
        raise ValueError(f"Unable to read override file for {env_name}") from exc
    if size > max_bytes:
        raise ValueError(
            f"Override file for {env_name} is too large (>{max_bytes} bytes)"
        )
    try:
        return path.read_text(encoding="utf-8")
    except UnicodeDecodeError as exc:
        raise ValueError(
            f"Override file for {env_name} must be valid UTF-8 text"
        ) from exc
    except OSError as exc:
        raise ValueError(f"Unable to read override file for {env_name}") from exc


def _youtube_upload_resolve_metadata(
    root_dir: Path, run_id: str
) -> tuple[str, str, list[str]]:
    title = None
    description = None
    tags: list[str] | None = None

    metadata_path = root_dir / "output" / run_id / "metadata.json"
    metadata = _youtube_upload_read_json_if_dict(metadata_path)
    if metadata:
        raw_title = metadata.get("title")
        if isinstance(raw_title, str) and raw_title != "":
            title = raw_title
        raw_description = metadata.get("description")
        if isinstance(raw_description, str) and raw_description != "":
            description = raw_description
        raw_tags = metadata.get("tags")
        if isinstance(raw_tags, list):
            tags = [item for item in raw_tags if isinstance(item, str)]

    if title is None:
        title_path = _youtube_upload_resolve_override_path(
            root_dir, "YOUTUBE_TITLE_PATH"
        )
        if title_path is not None:
            title = _youtube_upload_read_override_text(title_path, "YOUTUBE_TITLE_PATH")

    if description is None:
        description_path = _youtube_upload_resolve_override_path(
            root_dir, "YOUTUBE_DESCRIPTION_PATH"
        )
        if description_path is not None:
            description = _youtube_upload_read_override_text(
                description_path, "YOUTUBE_DESCRIPTION_PATH"
            )

    if tags is None:
        tags_path = _youtube_upload_resolve_override_path(root_dir, "YOUTUBE_TAGS_PATH")
        if tags_path is not None:
            tags_text = _youtube_upload_read_override_text(
                tags_path, "YOUTUBE_TAGS_PATH"
            )
            tags = _youtube_upload_parse_tags_text(tags_text)

    if title is None:
        title = f"Dhamma Video - {run_id}"
    if description is None:
        description = "Generated by Dhamma Channel Automation."
    if tags is None:
        tags = []

    return title, description, tags


def _youtube_upload_extract_http_status(exc: Exception) -> int | None:
    if isinstance(exc, youtube_upload.YoutubeApiError):
        return exc.status
    for attr in ("status", "status_code"):
        value = getattr(exc, attr, None)
        if isinstance(value, int):
            return value
    resp = getattr(exc, "resp", None)
    status = getattr(resp, "status", None)
    if isinstance(status, int):
        return status
    return None


def agent_youtube_upload(step, run_dir: Path):
    """‡πÄ‡∏≠‡πÄ‡∏à‡∏ô‡∏ï‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î YouTube - ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå MP4 ‡∏Ç‡∏∂‡πâ‡∏ô YouTube ‡∏û‡∏£‡πâ‡∏≠‡∏° retry ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

    ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏Ñ‡∏ß‡∏£‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ú‡πà‡∏≤‡∏ô orchestrator ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ guardrails ‡πÄ‡∏ä‡πà‡∏ô
    `PIPELINE_ENABLED` ‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    """
    run_id = run_dir.name
    root_dir = ROOT.resolve()

    YU_ENGINE = "youtube.upload"
    CODE_UPLOAD_DISABLED = "upload_disabled"
    CODE_QUALITY_NOT_PASS = "quality_gate_not_pass"
    CODE_INPUT_MP4_MISSING = "input_mp4_missing"
    CODE_AUTH_MISSING_ENV = "auth_missing_env"
    CODE_DEPS_MISSING = "youtube_deps_missing"
    CODE_YOUTUBE_API_ERROR = "youtube_api_error"
    CODE_FAILED_AFTER_RETRIES = "upload_failed_after_retries"

    upload_enabled = _youtube_upload_is_enabled(step)
    max_retries = _youtube_upload_parse_int_env("YOUTUBE_UPLOAD_MAX_RETRIES", 3)
    backoff_seconds = _youtube_upload_parse_int_env(
        "YOUTUBE_UPLOAD_BACKOFF_SECONDS", 10
    )
    privacy_status_raw = (
        os.environ.get("YOUTUBE_PRIVACY_STATUS", "unlisted").strip().lower()
    )
    if privacy_status_raw not in ("private", "unlisted", "public"):
        log(
            f"Invalid YOUTUBE_PRIVACY_STATUS='{privacy_status_raw}', falling back to 'unlisted'",
            "WARN",
        )
        privacy_status = "unlisted"
    else:
        privacy_status = privacy_status_raw

    checked_at = datetime.now(tz=UTC).isoformat().replace("+00:00", "Z")
    upload_summary_rel = (
        Path("output") / run_id / "artifacts" / "youtube_upload_summary.json"
    )
    upload_summary_path = root_dir / upload_summary_rel

    title, description, tags = _youtube_upload_resolve_metadata(root_dir, run_id)
    quality_rel = _youtube_upload_expected_quality_summary_rel(run_id)

    output_mp4_rel = ""

    def _write_summary(
        decision: str,
        attempt_count: int,
        error_code: str | None = None,
        error_message: str | None = None,
        video_id: str | None = None,
    ) -> str:
        video_url = None
        if video_id:
            video_url = f"https://www.youtube.com/watch?v={video_id}"
        error = None
        if error_code is not None:
            error = {
                "code": error_code,
                "message": error_message or "",
            }

        summary = {
            "schema_version": "v1",
            "run_id": run_id,
            "engine": YU_ENGINE,
            "checked_at": checked_at,
            "quality_gate_summary": quality_rel,
            "input_mp4_path": output_mp4_rel,
            "decision": decision,
            "privacy_status": privacy_status,
            "attempt_count": attempt_count,
            "max_retries": max_retries,
            "backoff_seconds": backoff_seconds,
            "video_id": video_id,
            "video_url": video_url,
            "error": error,
            "metadata": {
                "title": title,
                "description": description,
                "tags": tags,
            },
        }
        write_json(upload_summary_path, summary)
        return upload_summary_rel.as_posix()

    if not upload_enabled:
        summary_path = _write_summary(
            decision="skipped",
            attempt_count=0,
            error_code=CODE_UPLOAD_DISABLED,
            error_message="YouTube upload disabled",
        )
        log(
            f"YouTube upload skipped; decision=skipped; code={CODE_UPLOAD_DISABLED}; attempt=0",
            "INFO",
        )
        return summary_path

    quality_summary_required = _youtube_upload_load_quality_summary_required(
        root_dir, run_id
    )
    quality_decision = quality_summary_required.get("decision")

    # Extract and validate output_mp4_path from quality summary (once)
    output_mp4_value = quality_summary_required.get("output_mp4_path")
    if isinstance(output_mp4_value, str) and output_mp4_value:
        output_mp4_rel = Path(output_mp4_value).as_posix()
        output_mp4_abs = _youtube_upload_validate_repo_relative_path(
            root_dir, output_mp4_rel, "quality_gate_summary.output_mp4_path"
        )
    else:
        if quality_decision == "pass":
            raise ValueError("quality_gate_summary.output_mp4_path is required")
        output_mp4_abs = None

    if quality_decision != "pass":
        summary_path = _write_summary(
            decision="skipped",
            attempt_count=0,
            error_code=CODE_QUALITY_NOT_PASS,
            error_message="Quality gate decision not pass",
        )
        log(
            f"YouTube upload skipped; decision=skipped; code={CODE_QUALITY_NOT_PASS}; attempt=0",
            "INFO",
        )
        return summary_path

    # At this point, quality_decision == "pass" and output_mp4_abs must be valid
    if output_mp4_abs is None:
        raise ValueError("quality_gate_summary.output_mp4_path is required")

    if not output_mp4_abs.is_file() or output_mp4_abs.stat().st_size <= 0:
        _write_summary(
            decision="failed",
            attempt_count=0,
            error_code=CODE_INPUT_MP4_MISSING,
            error_message="Input MP4 missing or empty",
        )
        log(
            f"YouTube upload failed; decision=failed; code={CODE_INPUT_MP4_MISSING}; attempt=0",
            "ERROR",
        )
        raise RuntimeError(
            f"YouTube upload failed for run_id={run_id}; code={CODE_INPUT_MP4_MISSING}"
        )

    total_attempts = 1 + max_retries
    attempt = 0
    while attempt < total_attempts:
        attempt += 1
        try:
            video_id = youtube_upload.upload_video(
                output_mp4_abs, title, description, tags, privacy_status
            )
            summary_path = _write_summary(
                decision="uploaded",
                attempt_count=attempt,
                video_id=video_id,
            )
            log(
                f"YouTube upload completed; decision=uploaded; attempt={attempt}",
                "SUCCESS",
            )
            return summary_path
        except youtube_upload.YoutubeDepsMissingError as exc:
            _write_summary(
                decision="failed",
                attempt_count=attempt,
                error_code=CODE_DEPS_MISSING,
                error_message="YouTube dependencies are not installed",
            )
            log(
                f"YouTube upload failed; decision=failed; code={CODE_DEPS_MISSING}; attempt={attempt}",
                "ERROR",
            )
            raise RuntimeError(
                f"YouTube upload failed for run_id={run_id}; code={CODE_DEPS_MISSING}"
            ) from exc
        except youtube_upload.YoutubeAuthMissingError as exc:
            _write_summary(
                decision="failed",
                attempt_count=attempt,
                error_code=CODE_AUTH_MISSING_ENV,
                error_message="Missing YouTube auth environment variables",
            )
            log(
                f"YouTube upload failed; decision=failed; code={CODE_AUTH_MISSING_ENV}; attempt={attempt}",
                "ERROR",
            )
            raise RuntimeError(
                f"YouTube upload failed for run_id={run_id}; code={CODE_AUTH_MISSING_ENV}"
            ) from exc
        except Exception as exc:
            status = _youtube_upload_extract_http_status(exc)
            retryable = status == 429 or (status is not None and 500 <= status < 600)
            if retryable and attempt < total_attempts:
                log(
                    "YouTube upload attempt "
                    f"{attempt}/{total_attempts} failed; decision=retry; code={CODE_YOUTUBE_API_ERROR}",
                    "WARN",
                )
                time.sleep(backoff_seconds)
                continue

            if retryable:
                error_code = CODE_FAILED_AFTER_RETRIES
                error_message = "YouTube upload failed after retries"
            else:
                error_code = CODE_YOUTUBE_API_ERROR
                error_message = "YouTube API error"

            _write_summary(
                decision="failed",
                attempt_count=attempt,
                error_code=error_code,
                error_message=error_message,
            )
            log(
                f"YouTube upload failed; decision=failed; code={error_code}; attempt={attempt}",
                "ERROR",
            )
            raise RuntimeError(
                f"YouTube upload failed for run_id={run_id}; code={error_code}"
            ) from exc


def agent_localization(step, run_dir: Path):
    """Localization & Subtitle - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    in_path.read_text(encoding="utf-8")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á SRT template
    srt_content = """1
00:00:00,000 --> 00:00:05,000
‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡∏°‡∏ó‡∏∏‡∏Å‡∏ó‡πà‡∏≤‡∏ô üôè

2
00:00:05,000 --> 00:00:10,000
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ñ‡∏¢‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î ‡πÉ‡∏à‡∏ü‡∏∏‡πâ‡∏á‡∏ã‡πà‡∏≤‡∏ô
‡∏à‡∏ô‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏∞‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πà‡∏≠‡∏ô‡∏î‡∏µ‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?

3
00:00:12,000 --> 00:00:17,000
‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏¢‡∏∏‡∏Ñ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ï‡πá‡∏°‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πà‡∏á‡∏£‡∏µ‡∏ö
‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡∏ó‡πà‡∏ß‡∏°‡∏ó‡πâ‡∏ô

4
00:00:17,000 --> 00:00:22,000
‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏à‡∏¥‡∏ï‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡∏û‡∏±‡∏Å
‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡∏™‡∏á‡∏ö‡πÄ‡∏•‡∏¢

5
00:00:24,000 --> 00:00:30,000
‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏ú‡∏°‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ ‡πÅ‡∏Ñ‡πà 5 ‡∏ô‡∏≤‡∏ó‡∏µ
‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ß‡∏•‡∏≤

6
00:00:30,000 --> 00:00:35,000
‡∏Ñ‡∏∏‡∏ì‡∏Å‡πá‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏à‡∏™‡∏á‡∏ö‡∏•‡∏á‡πÑ‡∏î‡πâ

... [continues]
"""

    localization = {
        "generated_at": datetime.now().isoformat(),
        "primary_language": "th",
        "subtitles": {
            "thai": {
                "filename": "subtitles_th.srt",
                "status": "generated",
                "total_lines": 120,
                "format": "SRT",
                "encoding": "UTF-8",
                "font_recommendation": "Prompt, Kanit",
                "size": "Medium (not too small)",
                "position": "Bottom center",
                "style": {
                    "color": "White",
                    "outline": "Black (2px)",
                    "background": "Semi-transparent black (optional)",
                },
            },
            "english": {
                "filename": "subtitles_en.srt",
                "status": "to_be_translated",
                "target_audience": "International Buddhists, meditation practitioners",
                "notes": "Translate key terms carefully: ‡∏™‡∏ï‡∏¥ = mindfulness/awareness",
            },
        },
        "translation_guide": {
            "key_terms": {
                "‡∏™‡∏ï‡∏¥": "mindfulness / awareness",
                "‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥": "mindfulness of breathing / breath meditation",
                "‡∏û‡∏£‡∏∞‡πÑ‡∏ï‡∏£‡∏õ‡∏¥‡∏é‡∏Å": "Tripitaka / Pali Canon",
                "‡∏ß‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡∏°‡∏£‡∏£‡∏Ñ": "Visuddhimagga / Path of Purification",
                "‡∏Å‡∏£‡∏£‡∏°‡∏ê‡∏≤‡∏ô": "meditation object / kamma·π≠·π≠hƒÅna",
                "‡∏™‡∏°‡∏≤‡∏ò‡∏¥": "concentration / samadhi",
            },
            "cultural_notes": [
                "üôè emoji = wai gesture (Thai greeting)",
                "Keep Thai Buddhist terminology intact when appropriate",
                "Add footnotes for untranslatable concepts",
            ],
        },
        "accessibility": {
            "closed_captions": {
                "enabled": True,
                "includes_sound_effects": "[‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥]",
                "speaker_labels": "[‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢]",
            },
            "auto_generated": {
                "youtube_auto_captions": "available as backup",
                "accuracy": "60-70% (Thai)",
                "recommendation": "Always upload custom SRT",
            },
        },
        "srt_file_preview": srt_content[:500] + "...",
        "tools_recommended": [
            "Subtitle Edit (free, Windows)",
            "Aegisub (free, cross-platform)",
            "YouTube Studio (built-in editor)",
            "Rev.com (paid transcription service)",
        ],
        "quality_checklist": [
            "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á",
            "‡πÅ‡∏ö‡πà‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 2 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î)",
            "‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• 1-7 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ/‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î",
            "‡πÉ‡∏ä‡πâ emoji ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î",
            "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏∞‡∏Å‡∏î‡∏Ñ‡∏≥",
        ],
        "estimated_time": "2-3 hours (manual timing)",
    }

    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå SRT ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    srt_path = run_dir / "subtitles_th.srt"
    write_text(srt_path, srt_content)

    write_json(out, localization)
    log(
        f"‚úì Localization completed - Thai SRT generated ({localization['subtitles']['thai']['total_lines']} lines)"
    )
    return out


def agent_thumbnail_generator(step, run_dir: Path):
    """Thumbnail Generator - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ã‡πá‡∏õ‡∏ï‡πå‡∏†‡∏≤‡∏û‡∏õ‡∏Å"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    metadata = read_json(in_path)
    title = metadata.get("title", "")

    thumbnail_concepts = {
        "generated_at": datetime.now().isoformat(),
        "video_title": title,
        "dimensions": "1280x720 px (16:9)",
        "file_format": "JPG or PNG",
        "file_size_limit": "2MB (YouTube)",
        "concepts": [
            {
                "concept_id": 1,
                "title": "Peaceful Meditation",
                "text_overlay": {
                    "main": "‡∏ù‡∏∂‡∏Å‡∏™‡∏ï‡∏¥ 5 ‡∏ô‡∏≤‡∏ó‡∏µ",
                    "sub": "‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà",
                    "font_size": {"main": "72pt", "sub": "36pt"},
                    "font": "Kanit Bold",
                    "color": "White + Gold",
                    "stroke": "Dark shadow (3px)",
                },
                "visual_elements": [
                    "Person meditating (silhouette or clear face)",
                    "Natural background (sunset, mountains)",
                    "Soft glow/light effect",
                    "üôè emoji (optional)",
                ],
                "color_scheme": "warm (orange/gold)",
                "emotion": "peaceful, inviting",
                "composition": "Rule of thirds - subject on right, text on left",
            },
            {
                "concept_id": 2,
                "title": "Modern Minimal",
                "text_overlay": {
                    "main": "5 ‡∏ô‡∏≤‡∏ó‡∏µ",
                    "sub": "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÉ‡∏à",
                    "badge": "üßò ‡∏™‡∏ï‡∏¥",
                    "font_size": {"main": "120pt", "sub": "48pt"},
                    "font": "Prompt ExtraBold",
                    "color": "Dark blue + White",
                    "style": "Clean, modern",
                },
                "visual_elements": [
                    "Minimalist breath animation",
                    "Geometric shapes (circles/waves)",
                    "Gradient background (blue to green)",
                    "NO clutter",
                ],
                "color_scheme": "cool (blue/green)",
                "emotion": "modern, trustworthy",
                "composition": "Center-aligned, symmetrical",
            },
            {
                "concept_id": 3,
                "title": "Emotional Hook",
                "text_overlay": {
                    "main": "‡πÉ‡∏à‡∏ü‡∏∏‡πâ‡∏á‡∏ã‡πà‡∏≤‡∏ô?",
                    "sub": "5 ‡∏ô‡∏≤‡∏ó‡∏µ ‡πÅ‡∏Å‡πâ‡πÑ‡∏î‡πâ!",
                    "font_size": {"main": "80pt", "sub": "52pt"},
                    "font": "Kanit Bold",
                    "color": "Yellow + White",
                    "effect": "Slight tilt (dynamic)",
                },
                "visual_elements": [
                    "Split screen: stressed vs calm face",
                    "Before/After concept",
                    "Arrows or transformation symbol",
                    "High contrast",
                ],
                "color_scheme": "contrast (yellow/dark)",
                "emotion": "curiosity, problem-solving",
                "composition": "Dynamic split, eye-catching",
            },
        ],
        "design_principles": {
            "readability": "Text readable on mobile (4-6 words max)",
            "contrast": "High contrast text/background",
            "branding": "Consistent with channel style",
            "emotion": "Show face when possible (5x higher CTR)",
            "curiosity": "Ask question or promise benefit",
        },
        "tools": {
            "free": [
                "Canva (template available)",
                "Photopea (free Photoshop alternative)",
                "GIMP",
            ],
            "paid": ["Adobe Photoshop", "Affinity Photo", "Figma"],
        },
        "a_b_testing": {
            "recommendation": "Create 2-3 versions, test which gets higher CTR",
            "test_duration": "7-14 days",
            "metrics": "CTR (Click-Through Rate)",
        },
        "best_practices": [
            "‡πÉ‡∏ä‡πâ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ô‡∏à‡∏£‡∏¥‡∏á (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ)",
            "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 6 ‡∏Ñ‡∏≥",
            "‡∏™‡∏µ‡∏™‡∏±‡∏ô‡∏™‡∏î‡πÉ‡∏™ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏â‡∏π‡∏î‡∏â‡∏≤‡∏î",
            "‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (‡πÑ‡∏°‡πà clickbait)",
            "‡πÄ‡∏û‡∏¥‡πà‡∏° emoji 1-2 ‡∏ï‡∏±‡∏ß (optional)",
        ],
        "avoid": [
            "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏¢‡∏≠‡∏∞‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ",
            "‡∏™‡∏µ‡∏à‡∏≤‡∏á‡∏à‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å",
            "‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤",
            "Clickbait ‡∏´‡∏•‡∏≠‡∏Å‡∏•‡∏ß‡∏á",
        ],
    }

    write_json(out, thumbnail_concepts)
    log(
        f"‚úì Thumbnail concepts created - {len(thumbnail_concepts['concepts'])} designs ready"
    )
    return out


def agent_format_conversion(step, run_dir: Path):
    """Format Conversion - ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    in_path.read_text(encoding="utf-8")

    formats = {
        "converted_at": datetime.now().isoformat(),
        "source_file": str(in_path),
        "conversions": {
            "video": {
                "youtube": {
                    "format": "MP4",
                    "codec": "H.264",
                    "resolution": "1920x1080 (1080p)",
                    "frame_rate": "30fps",
                    "bitrate": "8-12 Mbps",
                    "audio": "AAC 320kbps",
                    "max_file_size": "128GB",
                    "aspect_ratio": "16:9",
                },
                "facebook": {
                    "format": "MP4",
                    "resolution": "1280x720 (720p)",
                    "aspect_ratio": "16:9 or 1:1 (square)",
                    "max_duration": "240 min",
                    "max_file_size": "10GB",
                },
                "tiktok_shorts": {
                    "format": "MP4",
                    "resolution": "1080x1920 (vertical)",
                    "aspect_ratio": "9:16",
                    "max_duration": "10 min",
                    "recommendation": "Extract key 60-90 sec clips",
                },
            },
            "audio": {
                "podcast": {
                    "format": "MP3",
                    "bitrate": "192kbps",
                    "sample_rate": "44.1kHz",
                    "use_case": "Audio-only version for podcast platforms",
                }
            },
            "document": {
                "pdf": {
                    "filename": "script_formatted.pdf",
                    "use_case": "Printable script for reference",
                    "include": ["Full script", "Citations", "Timestamps"],
                },
                "docx": {
                    "filename": "script_editable.docx",
                    "use_case": "Editable for future revisions",
                },
            },
        },
        "export_settings": {
            "premiere_pro": {
                "sequence": "1920x1080, 30fps",
                "export_preset": "YouTube 1080p Full HD",
            },
            "davinci_resolve": {
                "timeline": "1920x1080, 30fps",
                "delivery": "YouTube preset",
            },
            "final_cut_pro": {"destination": "YouTube & Facebook"},
        },
        "optimization": {
            "compress_without_quality_loss": {
                "tool": "HandBrake",
                "preset": "Fast 1080p30",
            },
            "thumbnail": {
                "extract_frame": "at 02:30 (engaging moment)",
                "resolution": "1280x720",
            },
        },
        "delivery_checklist": [
            "MP4 for YouTube (1080p)",
            "SRT subtitle file",
            "Thumbnail JPG (1280x720)",
            "Metadata JSON",
            "PDF script (backup)",
        ],
    }

    write_json(out, formats)
    log(
        f"‚úì Format conversion specs created - {len(formats['conversions'])} format categories"
    )
    return out


def agent_multi_channel_publish(step, run_dir: Path):
    """Multi-Channel Publish - ‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°"""
    in_path = run_dir / step["input_from"]
    out = run_dir / step["output"]

    metadata = read_json(in_path)

    multi_channel = {
        "published_at": datetime.now().isoformat(),
        "status": "ready_for_distribution",
        "platforms": {
            "youtube": {
                "enabled": True,
                "priority": 1,
                "settings": {
                    "title": metadata.get("title", ""),
                    "description": metadata.get("description", ""),
                    "tags": metadata.get("tags", []),
                    "category": "Education",
                    "visibility": "public",
                    "publish_time": "2025-11-05 10:00:00 +07:00",
                    "playlist": "‡∏ò‡∏£‡∏£‡∏°‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô",
                    "thumbnail": "thumbnail.jpg",
                    "end_screen": True,
                    "cards": True,
                    "subtitles": "subtitles_th.srt",
                },
                "api_endpoint": "YouTube Data API v3",
                "status": "scheduled",
            },
            "facebook": {
                "enabled": True,
                "priority": 2,
                "targets": [
                    {
                        "type": "page",
                        "name": "Dhamma Channel",
                        "post_text": "üôè ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÉ‡∏´‡∏°‡πà! ‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏™‡∏ï‡∏¥‡πÉ‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô 5 ‡∏ô‡∏≤‡∏ó‡∏µ\n\n‡∏°‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å '‡∏≠‡∏≤‡∏ô‡∏≤‡∏õ‡∏≤‡∏ô‡∏™‡∏ï‡∏¥' ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ß‡∏•‡∏≤\n\n‚ú® ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:\n‚Ä¢ ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î\n‚Ä¢ ‡πÉ‡∏à‡∏™‡∏á‡∏ö\n‚Ä¢ ‡∏ô‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏ö‡∏™‡∏ô‡∏¥‡∏ó\n\n‡∏î‡∏π‡πÄ‡∏ï‡πá‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà: [YouTube Link]",
                        "hashtags": ["#‡∏ò‡∏£‡∏£‡∏°‡∏∞", "#‡∏™‡∏ï‡∏¥", "#mindfulness"],
                        "schedule": "same_as_youtube",
                    },
                    {
                        "type": "group",
                        "name": "‡∏ò‡∏£‡∏£‡∏°‡∏∞‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï",
                        "permission": "request_approval",
                    },
                ],
            },
            "line": {
                "enabled": False,
                "targets": [
                    {
                        "type": "broadcast",
                        "message": "üôè ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ò‡∏£‡∏£‡∏°‡∏∞‡πÉ‡∏´‡∏°‡πà\n\n‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏™‡∏ï‡∏¥‡πÉ‡∏ô 5 ‡∏ô‡∏≤‡∏ó‡∏µ\n‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà: [Link]",
                        "image": "thumbnail.jpg",
                    }
                ],
                "note": "Enable when LINE OA is ready",
            },
            "tiktok": {
                "enabled": False,
                "note": "Create 60-90 sec vertical clips",
                "recommendation": "Extract key teaching moments",
                "aspect_ratio": "9:16",
            },
            "website": {
                "enabled": True,
                "priority": 3,
                "settings": {
                    "blog_post": {
                        "title": metadata.get("title", ""),
                        "content": "Embed YouTube + Full transcript",
                        "category": "Meditation",
                        "tags": metadata.get("tags", [])[:5],
                    },
                    "embed_code": "<iframe width='560' height='315' src='...'></iframe>",
                },
            },
        },
        "cross_promotion_schedule": {
            "day_0": {
                "time": "10:00",
                "action": "Publish to YouTube",
                "platforms": ["youtube"],
            },
            "day_0+2h": {
                "time": "12:00",
                "action": "Share to Facebook Page",
                "platforms": ["facebook"],
            },
            "day_0+4h": {
                "time": "14:00",
                "action": "Post to Website",
                "platforms": ["website"],
            },
            "day_1": {
                "time": "09:00",
                "action": "Share to Facebook Groups",
                "platforms": ["facebook_groups"],
            },
            "day_2": {
                "time": "10:00",
                "action": "LINE Broadcast (if enabled)",
                "platforms": ["line"],
            },
        },
        "analytics_tracking": {
            "utm_parameters": {
                "youtube": "?utm_source=youtube&utm_medium=video&utm_campaign=mindfulness_series",
                "facebook": "?utm_source=facebook&utm_medium=social&utm_campaign=mindfulness_series",
                "line": "?utm_source=line&utm_medium=broadcast&utm_campaign=mindfulness_series",
            },
            "metrics_to_track": [
                "views",
                "watch_time",
                "engagement_rate",
                "click_through_rate",
                "shares",
                "comments",
            ],
        },
        "automation_tools": [
            "Buffer (social media scheduling)",
            "Hootsuite (multi-platform posting)",
            "Zapier (workflow automation)",
            "YouTube Studio (native scheduling)",
        ],
    }

    write_json(out, multi_channel)
    log(
        f"‚úì Multi-Channel publish configured - {len([p for p in multi_channel['platforms'].values() if p.get('enabled')])} platforms enabled"
    )
    return out


def agent_publish(step, run_dir: Path):
    """Scheduling & Publishing - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡πÅ‡∏•‡∏∞‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ß‡∏•‡∏≤"""
    run_dir / step["input_from"]
    out = run_dir / step["output"]

    # ‡∏£‡∏±‡∏ö input ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå
    input_from = step.get("input_from", {})
    if isinstance(input_from, dict):
        script_file = input_from.get("script", "script_validated.md")
        metadata_file = input_from.get("metadata", "metadata.json")
    else:
        metadata_file = input_from
        script_file = "script_validated.md"

    run_dir / script_file if "/" in script_file or "\\" in script_file else run_dir / script_file
    metadata_path = (
        run_dir / metadata_file
        if "/" in metadata_file or "\\" in metadata_file
        else run_dir / metadata_file
    )

    # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    metadata = read_json(metadata_path) if metadata_path.exists() else {}

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà
    publish_config = {
        "scheduled_at": datetime.now().isoformat(),
        "status": "ready_to_publish",
        "platforms": ["youtube"],
        "youtube": {
            "video_file": "output/final_video.mp4",
            "title": metadata.get("title", ""),
            "description": metadata.get("description", ""),
            "tags": metadata.get("tags", []),
            "category": metadata.get("category", "Education"),
            "privacy": metadata.get("visibility", "public"),
            "publish_time": "tomorrow 10:00 +07:00",
            "playlist_id": None,
            "thumbnail": "output/thumbnail.jpg",
        },
        "checklist": {
            "video_file": False,
            "thumbnail": False,
            "script_approved": True,
            "metadata_ready": True,
            "doctrine_validated": True,
            "seo_optimized": True,
            "subtitles": False,
            "visual_assets": False,
            "voiceover": False,
        },
    }

    write_json(out, publish_config)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á checklist ‡πÅ‡∏¢‡∏Å
    checklist_md = f"""# üìã Complete Publish Checklist

## ‚úÖ Content Creation (Completed)
- [x] Trend Scout - Topics identified
- [x] Topic Prioritizer - Best topic selected
- [x] Research Retrieval - Citations gathered
- [x] Data Enrichment - Context added
- [x] Script Outline - Structure created
- [x] Script Writer - Full script written
- [x] Doctrine Validator - Approved ‚úÖ
- [x] Legal/Compliance - Compliant ‚úÖ

## ‚úÖ Production Assets (To Complete)
- [ ] Visual Asset Guide - Review B-roll list
- [ ] Voiceover - Record or generate
- [ ] Localization - Thai subtitles ready
- [ ] Thumbnail - Design 3 concepts, pick best
- [ ] Format Conversion - Export final MP4

## ‚úÖ Publishing (To Complete)
- [ ] SEO Metadata - Applied to video
- [ ] Multi-Channel - Schedule cross-posting
- [ ] Upload to YouTube
- [ ] Set publish time: {publish_config["youtube"]["publish_time"]}
- [ ] Add to playlist: "‡∏ò‡∏£‡∏£‡∏°‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô"
- [ ] Community post scheduled
- [ ] Backup/Archive - Save final package

## ‚úÖ Post-Publishing
- [ ] Monitor first 24h metrics
- [ ] Respond to comments (first 2-3 hours critical)
- [ ] Check retention rate
- [ ] Update analytics dashboard
- [ ] Share to Facebook/LINE (staggered)

## üìä Target Metrics (First Week)
- Views: 1,000+
- Watch Time: > 50% avg
- Likes: > 95%
- Comments: 20+
- Shares: 50+
"""

    checklist_path = run_dir / "publish_checklist.md"
    write_text(checklist_path, checklist_md)

    log(
        f"‚úì Publish configured - Scheduled for {publish_config['youtube']['publish_time']}"
    )
    log(f"‚úì Complete checklist created: {checklist_path}")
    return out


# ========== AGENT REGISTRY ==========

AGENTS = {
    # System Setup Phase
    "PromptPack": agent_prompt_pack,
    "AgentTemplate": agent_template,
    "Security": agent_security,
    "Integration": agent_integration,
    "DataSync": agent_data_sync,
    "InventoryIndex": agent_inventory_index,
    "Monitoring": agent_monitoring,
    "Notification": agent_notification,
    "ErrorFlag": agent_error_flag,
    "Dashboard": agent_dashboard,
    "BackupArchive": agent_backup_archive,
    # Video Workflow Phase
    "TrendScout": agent_trend_scout,
    "TopicPrioritizer": agent_topic_prioritizer,
    "ResearchRetrieval": agent_research_retrieval,
    "DataEnrichment": agent_data_enrichment,
    "ScriptOutline": agent_script_outline,
    "ScriptWriter": agent_script_writer,
    "DoctrineValidator": agent_doctrine_validator,
    "LegalCompliance": agent_legal_compliance,
    "VisualAsset": agent_visual_asset,
    "Voiceover": agent_voiceover,
    "voiceover.tts": agent_voiceover_tts,
    "video.render": agent_video_render,
    "quality.gate": agent_quality_gate,
    "youtube.upload": agent_youtube_upload,
    "Localization": agent_localization,
    "ThumbnailGenerator": agent_thumbnail_generator,
    "SEOAndMetadata": agent_seo_metadata,
    "FormatConversion": agent_format_conversion,
    "MultiChannelPublish": agent_multi_channel_publish,
    "SchedulingPublishing": agent_publish,
}


# ========== PIPELINE RUNNER ==========


def run_pipeline(pipeline_path: Path, run_id: str):
    """‡∏£‡∏±‡∏ô pipeline ‡∏ï‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå YAML"""
    log(f"Loading pipeline: {pipeline_path}")

    pipeline_enabled = parse_pipeline_enabled(os.environ.get("PIPELINE_ENABLED"))
    if not pipeline_enabled:
        log("Pipeline disabled by PIPELINE_ENABLED=false", "INFO")
        print("Pipeline disabled by PIPELINE_ENABLED=false")
        return {
            "pipeline": "unknown",
            "run_id": run_id,
            "started_at": datetime.now().isoformat(),
            "total_steps": 0,
            "successful": 0,
            "failed": 0,
            "results": {},
            "output_dir": str(ROOT / "output" / run_id),
            "status": "disabled",
        }

    with open(pipeline_path, encoding="utf-8") as f:
        cfg = yaml.safe_load(f)

    pipeline_name = cfg.get("pipeline", "unknown")
    steps = cfg.get("steps", [])

    log(f"Pipeline: {pipeline_name} ({len(steps)} steps)")

    run_dir = ROOT / "output" / run_id

    log(f"Output directory: {run_dir}")

    def _is_dry_run_step(step_cfg: dict) -> bool:
        config = step_cfg.get("config")
        if not isinstance(config, dict):
            return False
        return bool(config.get("dry_run", False))

    dry_run_only_pipeline = bool(steps) and all(
        _is_dry_run_step(step_cfg) for step_cfg in steps
    )

    results = {}

    for i, step in enumerate(steps, 1):
        step_id = step["id"]
        uses = step["uses"]

        log(f"[{i}/{len(steps)}] Running: {step_id} (uses: {uses})")

        agent_func = AGENTS.get(uses)
        if not agent_func:
            log(f"ERROR: Agent not implemented: {uses}", "ERROR")
            raise RuntimeError(f"Agent not implemented: {uses}")

        try:
            result = agent_func(step, run_dir)
            output_path = result
            planned_paths = None
            if isinstance(result, PlannedArtifacts):
                output_path = result.output_path
                if dry_run_only_pipeline:
                    planned_paths = result.planned_paths
            entry = {"status": "success", "output": str(output_path)}
            if planned_paths is not None:
                entry["planned_paths"] = planned_paths
            results[step_id] = entry
            log(f"[{i}/{len(steps)}] ‚úì {step_id} completed", "SUCCESS")
        except Exception as e:
            log(f"ERROR in {step_id}: {e}", "ERROR")
            results[step_id] = {"status": "error", "error": str(e)}
            raise

    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
    summary = {
        "pipeline": pipeline_name,
        "run_id": run_id,
        "started_at": datetime.now().isoformat(),
        "total_steps": len(steps),
        "successful": len([r for r in results.values() if r["status"] == "success"]),
        "failed": len([r for r in results.values() if r["status"] == "error"]),
        "results": results,
        "output_dir": str(run_dir),
    }

    if dry_run_only_pipeline:
        log("=" * 60)
        log("Pipeline completed (dry run) - no files were written")
        log("=" * 60)
        return summary

    summary_path = run_dir / "pipeline_summary.json"
    write_json(summary_path, summary)

    log("=" * 60)
    log(
        f"Pipeline completed: {summary['successful']}/{summary['total_steps']} steps successful"
    )
    log(f"Results saved to: {run_dir}")
    log("=" * 60)

    return summary


def main():
    parser = argparse.ArgumentParser(
        description="Dhamma Channel Automation - Orchestrator"
    )
    parser.add_argument("--pipeline", required=True, help="Path to YAML pipeline file")
    parser.add_argument("--run-id", default=None, help="Run ID (default: timestamp)")
    parser.add_argument(
        "--topic", default=None, help="Topic title to use (overrides mock data)"
    )

    args = parser.parse_args()

    # Check global kill switch (PIPELINE_ENABLED)
    pipeline_enabled = parse_pipeline_enabled(os.environ.get("PIPELINE_ENABLED"))

    if not pipeline_enabled:
        log("Pipeline disabled by PIPELINE_ENABLED=false", "INFO")
        print("Pipeline disabled by PIPELINE_ENABLED=false")
        return 0  # Exit successfully (no-op)

    if args.run_id is None:
        args.run_id = f"run_{int(time.time())}"

    # Store topic in environment for agents to access
    if args.topic:
        os.environ["DHAMMA_TOPIC"] = args.topic

    pipeline_path = Path(args.pipeline)

    if not pipeline_path.exists():
        print(f"ERROR: Pipeline file not found: {pipeline_path}")
        return 1

    try:
        run_pipeline(pipeline_path, args.run_id)
        return 0
    except Exception as e:
        log(f"Pipeline failed: {e}", "ERROR")
        return 1


if __name__ == "__main__":
    exit(main())
